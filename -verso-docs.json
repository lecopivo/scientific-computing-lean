{"99":
 "<code>SciLean.DataArrayN.reduceD {I X : Type} [IndexType I] [PlainDataType X] (x : X^[I]) (f : X → X → X) (default : X) : X</code>",
 "98":
 "<code>SciLean.DataArrayN.foldl {I X : Type} [IndexType I] [PlainDataType X] (x : X^[I]) (op : X → X → X) (init : X) : X</code>",
 "97":
 "<code>SciLean.DataArrayN.mapIdxMono {I X : Type} [IndexType I] [PlainDataType X] (x : X^[I]) (f : I → X → X) : X^[I]</code>",
 "96": "<code>Fin 2</code>",
 "95":
 "<code>SciLean.Scalar.sqrt.{u_1, u_2} {R : outParam (Type u_1)} {K : semiOutParam (Type u_2)} [self : Scalar R K] (x : K) : K</code>",
 "94":
 "<code>SciLean.DataArrayN.mapMono {I X : Type} [IndexType I] [PlainDataType X] (x : X^[I]) (f : X → X) : X^[I]</code>",
 "93": "<code>Float → Float</code>",
 "92":
 "<code>_root_.map {I : Type} [IndexType I] (x : Float^[I]) (f : Float → Float) : Float^[I]</code>",
 "91":
 "<code>SciLean.DataArrayN.uncurry {α : Type} [pd : PlainDataType α] {ι : Type} [IndexType ι] {κ : Type} [IndexType κ]\n  [Inhabited α] (x : α^[κ]^[ι]) : α^[ι, κ]</code>",
 "90": "<code>Float^[n, I]</code>",
 "9":
 "<code class=\"docstring\">`return e` inside of a `do` block makes the surrounding block evaluate to `pure e`,\nskipping any further statements.\nNote that uses of the `do` keyword in other syntax like in `for _ in _ do`\ndo not constitute a surrounding block in this sense;\nin supported editors, the corresponding `do` keyword of the surrounding block\nis highlighted when hovering over `return`.\n\n`return` not followed by a term starting on the same line is equivalent to `return ()`.\n</code>",
 "89":
 "<code>_root_.covariance' {n : ℕ} {I : Type} [IndexType I] [DecidableEq I] (x : Float^[I]^[n]) : Float^[I, I]</code>",
 "88": "<code>I</code>",
 "87":
 "<code>mean' {n : ℕ} {I : Type} [IndexType I] [DecidableEq I] (x : Float^[I]^[n]) : Float^[I]</code>",
 "86": "<code>Float^[I]</code>",
 "85":
 "<code>_root_.covariance {n : ℕ} {I : Type} [IndexType I] [DecidableEq I] (x : Float^[I]^[n]) : Float^[I, I]</code>",
 "84": "<code>Float^[I]^[n]</code>",
 "83":
 "<code>_root_.mean' {n : ℕ} {I : Type} [IndexType I] [DecidableEq I] (x : Float^[I]^[n]) : Float^[I]</code>",
 "82": "<code>mean {n : ℕ} (x : Float^[n]) : Float</code>",
 "81": "<code>Float</code>",
 "80":
 "<code class=\"docstring\">`let` is used to declare a local definition. Example:\n```\nlet x := 1\nlet y := x + 1\nx + y\n```\nSince functions are first class citizens in Lean, you can use `let` to declare\nlocal functions too.\n```\nlet double := fun x =&gt; 2*x\ndouble (double 3)\n```\nFor recursive definitions, you should use `let rec`.\nYou can also perform pattern matching using `let`. For example,\nassume `p` has type `Nat × Nat`, then you can write\n```\nlet (x, y) := p\nx + y\n```\n</code>",
 "8":
 "<code class=\"docstring\">`for x in e do s`  iterates over `e` assuming `e`'s type has an instance of the `ForIn` typeclass.\n`break` and `continue` are supported inside `for` loops.\n`for x in e, x2 in e2, ... do s` iterates of the given collections in parallel,\nuntil at least one of them is exhausted.\nThe types of `e2` etc. must implement the `ToStream` typeclass.\n</code>",
 "79": "<code>_root_.variance {n : ℕ} (x : Float^[n]) : Float</code>",
 "78": "<code>Nat.toFloat (n : ℕ) : Float</code>",
 "77": "<code>_root_.mean {n : ℕ} (x : Float^[n]) : Float</code>",
 "76":
 "<code>DecidableEq.{u} (α : Sort u) : Sort (max 1 u)</code><span class=\"sep\"></span><code class=\"docstring\">Asserts that `α` has decidable equality, that is, `a = b` is decidable\nfor all `a b : α`. See `Decidable`.\n</code>",
 "75":
 "<code>SciLean.DataArrayN.reshape {α : Type} [pd : PlainDataType α] {ι : Type} [IndexType ι] (x : α^[ι]) (κ : Type)\n  [IndexType κ] (hs : size κ = size ι) : α^[κ]</code>",
 "74":
 "<code class=\"docstring\">`/-- ... -/ #guard_msgs in cmd` captures the messages generated by the command `cmd`\nand checks that they match the contents of the docstring.\n\nBasic example:\n```lean\n/--\nerror: unknown identifier 'x'\n-/\n#guard_msgs in\nexample : α := x\n```\nThis checks that there is such an error and then consumes the message.\n\nBy default, the command captures all messages, but the filter condition can be adjusted.\nFor example, we can select only warnings:\n```lean\n/--\nwarning: declaration uses 'sorry'\n-/\n#guard_msgs(warning) in\nexample : α := sorry\n```\nor only errors\n```lean\n#guard_msgs(error) in\nexample : α := sorry\n```\nIn the previous example, since warnings are not captured there is a warning on `sorry`.\nWe can drop the warning completely with\n```lean\n#guard_msgs(error, drop warning) in\nexample : α := sorry\n```\n\nIn general, `#guard_msgs` accepts a comma-separated list of configuration clauses in parentheses:\n```\n#guard_msgs (configElt,*) in cmd\n```\nBy default, the configuration list is `(all, whitespace := normalized, ordering := exact)`.\n\nMessage filters (processed in left-to-right order):\n- `info`, `warning`, `error`: capture messages with the given severity level.\n- `all`: capture all messages (the default).\n- `drop info`, `drop warning`, `drop error`: drop messages with the given severity level.\n- `drop all`: drop every message.\n\nWhitespace handling (after trimming leading and trailing whitespace):\n- `whitespace := exact` requires an exact whitespace match.\n- `whitespace := normalized` converts all newline characters to a space before matching\n  (the default). This allows breaking long lines.\n- `whitespace := lax` collapses whitespace to a single space before matching.\n\nMessage ordering:\n- `ordering := exact` uses the exact ordering of the messages (the default).\n- `ordering := sorted` sorts the messages in lexicographic order.\n  This helps with testing commands that are non-deterministic in their ordering.\n\nFor example, `#guard_msgs (error, drop all) in cmd` means to check warnings and drop\neverything else.\n</code>",
 "73":
 "<code class=\"docstring\">`decide` attempts to prove the main goal (with target type `p`) by synthesizing an instance of `Decidable p`\nand then reducing that instance to evaluate the truth value of `p`.\nIf it reduces to `isTrue h`, then `h` is a proof of `p` that closes the goal.\n\nLimitations:\n- The target is not allowed to contain local variables or metavariables.\n  If there are local variables, you can try first using the `revert` tactic with these local variables\n  to move them into the target, which may allow `decide` to succeed.\n- Because this uses kernel reduction to evaluate the term, `Decidable` instances defined\n  by well-founded recursion might not work, because evaluating them requires reducing proofs.\n  The kernel can also get stuck reducing `Decidable` instances with `Eq.rec` terms for rewriting propositions.\n  These can appear for instances defined using tactics (such as `rw` and `simp`).\n  To avoid this, use definitions such as `decidable_of_iff` instead.\n\n## Examples\n\nProving inequalities:\n```lean\nexample : 2 + 2 ≠ 5 := by decide\n```\n\nTrying to prove a false proposition:\n```lean\nexample : 1 ≠ 1 := by decide\n/-\ntactic 'decide' proved that the proposition\n  1 ≠ 1\nis false\n-/\n```\n\nTrying to prove a proposition whose `Decidable` instance fails to reduce\n```lean\nopaque unknownProp : Prop\n\nopen scoped Classical in\nexample : unknownProp := by decide\n/-\ntactic 'decide' failed for proposition\n  unknownProp\nsince its 'Decidable' instance reduced to\n  Classical.choice ⋯\nrather than to the 'isTrue' constructor.\n-/\n```\n\n## Properties and relations\n\nFor equality goals for types with decidable equality, usually `rfl` can be used in place of `decide`.\n```lean\nexample : 1 + 1 = 2 := by decide\nexample : 1 + 1 = 2 := by rfl\n```\n</code>",
 "72":
 "<code>Eq.{u_1} {α : Sort u_1} : α → α → Prop</code><span class=\"sep\"></span><code class=\"docstring\">The equality relation. It has one introduction rule, `Eq.refl`.\nWe use `a = b` as notation for `Eq a b`.\nA fundamental property of equality is that it is an equivalence relation.\n```\nvariable (α : Type) (a b c d : α)\nvariable (hab : a = b) (hcb : c = b) (hcd : c = d)\n\nexample : a = d :=\n  Eq.trans (Eq.trans hab (Eq.symm hcb)) hcd\n```\nEquality is much more than an equivalence relation, however. It has the important property that every assertion\nrespects the equivalence, in the sense that we can substitute equal expressions without changing the truth value.\nThat is, given `h1 : a = b` and `h2 : p a`, we can construct a proof for `p b` using substitution: `Eq.subst h1 h2`.\nExample:\n```\nexample (α : Type) (a b : α) (p : α → Prop)\n        (h1 : a = b) (h2 : p a) : p b :=\n  Eq.subst h1 h2\n\nexample (α : Type) (a b : α) (p : α → Prop)\n    (h1 : a = b) (h2 : p a) : p b :=\n  h1 ▸ h2\n```\nThe triangle in the second presentation is a macro built on top of `Eq.subst` and `Eq.symm`, and you can enter it by typing `\\t`.\nFor more information: [Equality](https://lean-lang.org/theorem_proving_in_lean4/quantifiers_and_equality.html#equality)\n</code>",
 "71":
 "<code>Prod.{u, v} (α : Type u) (β : Type v) : Type (max u v)</code><span class=\"sep\"></span><code class=\"docstring\">Product type (aka pair). You can use `α × β` as notation for `Prod α β`.\nGiven `a : α` and `b : β`, `Prod.mk a b : Prod α β`. You can use `(a, b)`\nas notation for `Prod.mk a b`. Moreover, `(a, b, c)` is notation for\n`Prod.mk a (Prod.mk b c)`.\nGiven `p : Prod α β`, `p.1 : α` and `p.2 : β`. They are short for `Prod.fst p`\nand `Prod.snd p` respectively. You can also write `p.fst` and `p.snd`.\nFor more information: [Constructors with Arguments](https://lean-lang.org/theorem_proving_in_lean4/inductive_types.html?highlight=Prod#constructors-with-arguments)\n</code>",
 "70":
 "<code>SciLean.Size.size.{u} {α : Sort u} (a : α) [self : SciLean.Size a] : ℕ</code>",
 "7": "<code>Array ℕ</code>",
 "69":
 "<code class=\"docstring\">`by tac` constructs a term of the expected type by running the tactic(s) `tac`. </code>",
 "68":
 "<code>SciLean.DataArrayN.reshape {α : Type} [pd : SciLean.PlainDataType α] {ι : Type} [SciLean.IndexType ι] (x : α^[ι])\n  (κ : Type) [SciLean.IndexType κ] (hs : SciLean.size κ = SciLean.size ι) : α^[κ]</code>",
 "67":
 "<code class=\"docstring\">Same as `sorry` but makes sure that the term is of type `Prop`.\n\n`sorry_proof` is very useful when writing programs such that you do not accidantelly add `sorry`\nwhich would prevent compiler from generating executable code. </code>",
 "66": "<code>size (Fin n × Fin m) = A.size</code>",
 "65": "<code>DataArray Float</code>",
 "64":
 "<code>SciLean.DataArray.reserve {α : Type} [pd : PlainDataType α] (arr : DataArray α) (capacity : ℕ) : DataArray α</code><span class=\"sep\"></span><code class=\"docstring\">Makes sure that `arr` fits at least `n` elements of `α` </code>",
 "63":
 "<code>Inhabited.default.{u} {α : Sort u} [self : Inhabited α] : α</code><span class=\"sep\"></span><code class=\"docstring\">`default` is a function that produces a \"default\" element of any\n`Inhabited` type. This element does not have any particular specified\nproperties, but it is often an all-zeroes value. </code>",
 "62": "<code>DataArray Float</code>",
 "61":
 "<code>_root_.outerProduct'' {n m : ℕ} (x : Float^[n]) (y : Float^[m]) : Float^[n, m]</code>",
 "60":
 "<code>SciLean.fullRange.{u} (I : Type u) [IndexType I] : IndexType.Stream I</code>",
 "6": "<code>Id.run.{u_1} {α : Type u_1} (x : Id α) : α</code>",
 "59": "<code>Float^[n, m]</code>",
 "58": "<code>Fin m</code>",
 "57": "<code>Float^[m]</code>",
 "56":
 "<code>_root_.outerProduct {n m : ℕ} (x : Float^[n]) (y : Float^[m]) : Float^[n, m]</code>",
 "55": "<code>Fin 10</code>",
 "54":
 "<code>Fin (n : ℕ) : Type</code><span class=\"sep\"></span><code class=\"docstring\">`Fin n` is a natural number `i` with the constraint that `0 ≤ i &lt; n`.\nIt is the \"canonical type with `n` elements\".\n</code>",
 "53": "<code>Fin 10 → Float</code>",
 "52":
 "<code class=\"docstring\">Declares one or more typed variables, or modifies whether already-declared variables are\n  implicit.\n\nIntroduces variables that can be used in definitions within the same `namespace` or `section` block.\nWhen a definition mentions a variable, Lean will add it as an argument of the definition. This is\nuseful in particular when writing many definitions that have parameters in common (see below for an\nexample).\n\nVariable declarations have the same flexibility as regular function paramaters. In particular they\ncan be [explicit, implicit][binder docs], or [instance implicit][tpil classes] (in which case they\ncan be anonymous). This can be changed, for instance one can turn explicit variable `x` into an\nimplicit one with `variable {x}`. Note that currently, you should avoid changing how variables are\nbound and declare new variables at the same time; see [issue 2789] for more on this topic.\n\nIn *theorem bodies* (i.e. proofs), variables are not included based on usage in order to ensure that\nchanges to the proof cannot change the statement of the overall theorem. Instead, variables are only\navailable to the proof if they have been mentioned in the theorem header or in an `include` command\nor are instance implicit and depend only on such variables.\n\nSee [*Variables and Sections* from Theorem Proving in Lean][tpil vars] for a more detailed\ndiscussion.\n\n[tpil vars]:\nhttps://lean-lang.org/theorem_proving_in_lean4/dependent_type_theory.html#variables-and-sections\n(Variables and Sections on Theorem Proving in Lean) [tpil classes]:\nhttps://lean-lang.org/theorem_proving_in_lean4/type_classes.html (Type classes on Theorem Proving in\nLean) [binder docs]:\nhttps://leanprover-community.github.io/mathlib4_docs/Lean/Expr.html#Lean.BinderInfo (Documentation\nfor the BinderInfo type) [issue 2789]: https://github.com/leanprover/lean4/issues/2789 (Issue 2789\non github)\n\n## Examples\n\n```lean\nsection\n  variable\n    {α : Type u}      -- implicit\n    (a : α)           -- explicit\n    [instBEq : BEq α] -- instance implicit, named\n    [Hashable α]      -- instance implicit, anonymous\n\n  def isEqual (b : α) : Bool :=\n    a == b\n\n  #check isEqual\n  -- isEqual.{u} {α : Type u} (a : α) [instBEq : BEq α] (b : α) : Bool\n\n  variable\n    {a} -- `a` is implicit now\n\n  def eqComm {b : α} := a == b ↔ b == a\n\n  #check eqComm\n  -- eqComm.{u} {α : Type u} {a : α} [instBEq : BEq α] {b : α} : Prop\nend\n```\n\nThe following shows a typical use of `variable` to factor out definition arguments:\n\n```lean\nvariable (Src : Type)\n\nstructure Logger where\n  trace : List (Src × String)\n#check Logger\n-- Logger (Src : Type) : Type\n\nnamespace Logger\n  -- switch `Src : Type` to be implicit until the `end Logger`\n  variable {Src}\n\n  def empty : Logger Src where\n    trace := []\n  #check empty\n  -- Logger.empty {Src : Type} : Logger Src\n\n  variable (log : Logger Src)\n\n  def len :=\n    log.trace.length\n  #check len\n  -- Logger.len {Src : Type} (log : Logger Src) : Nat\n\n  variable (src : Src) [BEq Src]\n\n  -- at this point all of `log`, `src`, `Src` and the `BEq` instance can all become arguments\n\n  def filterSrc :=\n    log.trace.filterMap\n      fun (src', str') =&gt; if src' == src then some str' else none\n  #check filterSrc\n  -- Logger.filterSrc {Src : Type} (log : Logger Src) (src : Src) [inst✝ : BEq Src] : List String\n\n  def lenSrc :=\n    log.filterSrc src |&gt;.length\n  #check lenSrc\n  -- Logger.lenSrc {Src : Type} (log : Logger Src) (src : Src) [inst✝ : BEq Src] : Nat\nend Logger\n```\n\nThe following example demonstrates availability of variables in proofs:\n```lean\nvariable\n  {α : Type}    -- available in the proof as indirectly mentioned through `a`\n  [ToString α]  -- available in the proof as `α` is included\n  (a : α)       -- available in the proof as mentioned in the header\n  {β : Type}    -- not available in the proof\n  [ToString β]  -- not available in the proof\n\ntheorem ex : a = a := rfl\n```\nAfter elaboration of the proof, the following warning will be generated to highlight the unused\nhypothesis:\n```\nincluded section variable '[ToString α]' is not used in 'ex', consider excluding it\n```\nIn such cases, the offending variable declaration should be moved down or into a section so that\nonly theorems that do depend on it follow it until the end of the section.\n</code>",
 "51": "<code>A : Float^[2, 2]</code>",
 "50": "<code>_root_.A : Float^[2, 2]</code>",
 "5":
 "<code>Nat : Type</code><span class=\"sep\"></span><code class=\"docstring\">The type of natural numbers, starting at zero. It is defined as an\ninductive type freely generated by \"zero is a natural number\" and\n\"the successor of a natural number is a natural number\".\n\nYou can prove a theorem `P n` about `n : Nat` by `induction n`, which will\nexpect a proof of the theorem for `P 0`, and a proof of `P (succ i)` assuming\na proof of `P i`. The same method also works to define functions by recursion\non natural numbers: induction and recursion are two expressions of the same\noperation from Lean's point of view.\n\n```\nopen Nat\nexample (n : Nat) : n &lt; succ n := by\n  induction n with\n  | zero =&gt;\n    show 0 &lt; 1\n    decide\n  | succ i ih =&gt; -- ih : i &lt; succ i\n    show succ i &lt; succ (succ i)\n    exact Nat.succ_lt_succ ih\n```\n\nThis type is special-cased by both the kernel and the compiler:\n* The type of expressions contains \"`Nat` literals\" as a primitive constructor,\n  and the kernel knows how to reduce zero/succ expressions to nat literals.\n* If implemented naively, this type would represent a numeral `n` in unary as a\n  linked list with `n` links, which is horribly inefficient. Instead, the\n  runtime itself has a special representation for `Nat` which stores numbers up\n  to 2^63 directly and larger numbers use an arbitrary precision \"bignum\"\n  library (usually [GMP](https://gmplib.org/)).\n</code>",
 "49": "<code>Fin 3</code>",
 "48": "<code>u : Float^[3]</code>",
 "47": "<code>_root_.u : Float^[3]</code>",
 "46":
 "<code>SciLean.DataArray.size {α : Type} [pd : PlainDataType α] (self : DataArray α) : ℕ</code>",
 "45": "<code>DataArray X</code>",
 "44":
 "<code>SciLean.Size.size.{u} {α : Sort u} (a : α) [self : Size a] : ℕ</code>",
 "43":
 "<code>BasicOperations.DataArrayN.h_size {X I : Type} [PlainDataType X] [IndexType I] (self : DataArrayN X I) :\n  size I = self.data.size</code>",
 "42":
 "<code>BasicOperations.DataArrayN.data {X I : Type} [PlainDataType X] [IndexType I] (self : DataArrayN X I) : DataArray X</code>",
 "41": "<code>SciLean.IndexType.{u} (I : Type u) : Type u</code>",
 "40":
 "<code>SciLean.PlainDataType (α : Type) : Type</code><span class=\"sep\"></span><code class=\"docstring\">This rougly corresponds to Plain Old Data(POD)/Passive Data known from OOP\n\nwiki: https://en.wikipedia.org/wiki/Passive_data_structure\n\nWe distinguish between two main types of POD. `BitType` a type that is smaller or equal to a byte and `ByteType` that takes up multiple bytes. The main motivation is an efficient storage of `Array Bool` where `Bool` takes up only a single bit, so we can fit 8 bools into a single byte and achieve significant memore reduction.\n\nPotentially surprising edge case is array of fixed length, i.e. the type `{a : Array α // a.size = n}`. It is `PlainDataType` if `α` is `PlainDataType`. However, `Array α` is not `PlainDataType`, even if `α` is `PlainDataType`, as it does not have a fixed byte size.\n</code>",
 "4": "<code>ℕ</code>",
 "39": "<code>Type</code>",
 "38":
 "<code>BasicOperations.DataArrayN (X I : Type) [PlainDataType X] [IndexType I] : Type</code>",
 "37":
 "<code>BasicOperations.Fin.isLt {n : ℕ} (self : Fin n) : self.val &lt; n</code>",
 "36": "<code>BasicOperations.Fin.val {n : ℕ} (self : Fin n) : ℕ</code>",
 "35": "<code>BasicOperations.Fin (n : ℕ) : Type</code>",
 "34":
 "<code class=\"docstring\">`namespace &lt;id&gt;` opens a section with label `&lt;id&gt;` that influences naming and name resolution inside\nthe section:\n* Declarations names are prefixed: `def seventeen : ℕ := 17` inside a namespace `Nat` is given the\n  full name `Nat.seventeen`.\n* Names introduced by `export` declarations are also prefixed by the identifier.\n* All names starting with `&lt;id&gt;.` become available in the namespace without the prefix. These names\n  are preferred over names introduced by outer namespaces or `open`.\n* Within a namespace, declarations can be `protected`, which excludes them from the effects of\n  opening the namespace.\n\nAs with `section`, namespaces can be nested and the scope of a namespace is terminated by a\ncorresponding `end &lt;id&gt;` or the end of the file.\n\n`namespace` also acts like `section` in delimiting the scope of `variable`, `open`, and other scoped commands.\n</code>",
 "33": "<code>dot {n : ℕ} (x y : Float^[n]) : Float</code>",
 "32": "<code>Fin n</code>",
 "31": "<code>Float^[n]</code>",
 "30": "<code>_root_.dot {n : ℕ} (x y : Float^[n]) : Float</code>",
 "3": "<code>_root_.fibonacci (n : ℕ) : Array ℕ</code>",
 "29": "<code><span class=\"literal string\">\"hello\"</span> : String</code>",
 "28":
 "<code>String : Type</code><span class=\"sep\"></span><code class=\"docstring\">`String` is the type of (UTF-8 encoded) strings.\n\nThe compiler overrides the data representation of this type to a byte sequence,\nand both `String.utf8ByteSize` and `String.length` are cached and O(1).\n</code>",
 "27":
 "<code>Float : Type</code><span class=\"sep\"></span><code class=\"docstring\">Native floating point type, corresponding to the IEEE 754 *binary64* format\n(`double` in C or `f64` in Rust). </code>",
 "26": "<code>fibonacci (n : ℕ) : List ℕ</code>",
 "25":
 "<code class=\"docstring\">Pattern matching. `match e, ... with | p, ... =&gt; f | ...` matches each given\nterm `e` against each pattern `p` of a match alternative. When all patterns\nof an alternative match, the `match` term evaluates to the value of the\ncorresponding right-hand side `f` with the pattern variables bound to the\nrespective matched values.\nIf used as `match h : e, ... with | p, ... =&gt; f | ...`, `h : e = p` is available\nwithin `f`.\n\nWhen not constructing a proof, `match` does not automatically substitute variables\nmatched on in dependent variables' types. Use `match (generalizing := true) ...` to\nenforce this.\n\nSyntax quotations can also be used in a pattern match.\nThis matches a `Syntax` value against quotations, pattern variables, or `_`.\n\nQuoted identifiers only match identical identifiers - custom matching such as by the preresolved\nnames only should be done explicitly.\n\n`Syntax.atom`s are ignored during matching by default except when part of a built-in literal.\nFor users introducing new atoms, we recommend wrapping them in dedicated syntax kinds if they\nshould participate in matching.\nFor example, in\n```lean\nsyntax \"c\" (\"foo\" &lt;|&gt; \"bar\") ...\n```\n`foo` and `bar` are indistinguishable during matching, but in\n```lean\nsyntax foo := \"foo\"\nsyntax \"c\" (foo &lt;|&gt; \"bar\") ...\n```\nthey are not.\n</code>",
 "24": "<code>List ℕ</code>",
 "23":
 "<code>List.reverse.{u} {α : Type u} (as : List α) : List α</code><span class=\"sep\"></span><code class=\"docstring\">`O(|as|)`. Reverse of a list:\n* `[1, 2, 3, 4].reverse = [4, 3, 2, 1]`\n\nNote that because of the \"functional but in place\" optimization implemented by Lean's compiler,\nthis function works without any allocations provided that the input list is unshared:\nit simply walks the linked list and reverses all the node pointers.\n</code>",
 "220": "<code>_root_.matDot' {n m : ℕ} (A B : Float^[n, m]) : Float</code>",
 "22": "<code>fibonacci.go (n : ℕ) (l : List ℕ) : List ℕ</code>",
 "219": "<code>matDot.optimized {n m : ℕ} (A B : Float^[n, m]) : Float</code>",
 "218": "<code>Fin (n * m)</code>",
 "217":
 "<code>toFin_fromFin.{u_1} {I : Type u_1} [IndexType I] (i : Fin (size I)) : IndexType.toFin (IndexType.fromFin i) = i</code>",
 "216":
 "<code>SciLean.IndexType.fromFin.{u} {I : Type u} [self : IndexType I] : Fin (size I) → I</code>",
 "215": "<code>Fin (size (Fin n × Fin m))</code>",
 "214":
 "<code>SciLean.IndexType.sum_linearize.{u_1, u_2} {I : Type u_1} {X : Type u_2} [Add X] [Zero X] [IndexType I]\n  (f : I → X) : ∑ (i : I), f i = ∑ (i : Fin (size I)), f (IndexType.fromFin i)</code>",
 "213":
 "<code class=\"docstring\">`rw [rules]` applies the given list of rewrite rules to the target.\nSee the `rw` tactic for more information. </code>",
 "212": "<code>Fin n × Fin m</code>",
 "211": "<code>_root_.matDot {n m : ℕ} (A B : Float^[n, m]) : Float</code>",
 "210":
 "<code>matVecMul.optimized {n m : ℕ} (A : Float^[n, m]) (x : Float^[m]) : Float^[n]</code>",
 "21": "<code>_root_.fibonacci (n : ℕ) : List ℕ</code>",
 "209": "<code>Lean.pp.funBinderTypes</code>",
 "208":
 "<code>Fin.cast {n m : ℕ} (eq : n = m) (i : Fin n) : Fin m</code><span class=\"sep\"></span><code class=\"docstring\">`cast eq i` embeds `i` into an equal `Fin` type. </code>",
 "207":
 "<code>SciLean.IndexType.toFin.{u} {I : Type u} [self : IndexType I] : I → Fin (size I)</code>",
 "206":
 "<code>SciLean.DataArrayN.get {α : Type} [pd : PlainDataType α] {ι : Type} [IndexType ι] (xs : α^[ι]) (i : ι) : α</code>",
 "205":
 "<code>SciLean.ArrayType.get.{u, v, w} {Cont : Type u} {Idx : outParam (Type v)} {Elem : outParam (Type w)}\n  [self : ArrayType Cont Idx Elem] (cont : Cont) (i : Idx) : Elem</code>",
 "204":
 "<code>GetElem.getElem.{u, v, w} {coll : Type u} {idx : Type v} {elem : outParam (Type w)}\n  {valid : outParam (coll → idx → Prop)} [self : GetElem coll idx elem valid] (xs : coll) (i : idx) (h : valid xs i) :\n  elem</code><span class=\"sep\"></span><code class=\"docstring\">The syntax `arr[i]` gets the `i`'th element of the collection `arr`. If there\nare proof side conditions to the application, they will be automatically\ninferred by the `get_elem_tactic` tactic.\n</code>",
 "203":
 "<code>_root_.matVecMul {n m : ℕ} (A : Float^[n, m]) (x : Float^[m]) : Float^[n]</code>",
 "202":
 "<code>saxpy_naive.optimize_rule {n : ℕ} (a : Float) (x y : Float^[n]) : saxpy_naive a x y = saxpy_naive.optimized a x y</code>",
 "201":
 "<code>saxpy_naive {n : ℕ} (a : Float) (x y : Float^[n]) : Float^[n]</code>",
 "200":
 "<code>saxpy_naive.optimized {n : ℕ} (a : Float) (x y : Float^[n]) : Float^[n]</code>",
 "20":
 "<code>List.{u} (α : Type u) : Type u</code><span class=\"sep\"></span><code class=\"docstring\">`List α` is the type of ordered lists with elements of type `α`.\nIt is implemented as a linked list.\n\n`List α` is isomorphic to `Array α`, but they are useful for different things:\n* `List α` is easier for reasoning, and\n  `Array α` is modeled as a wrapper around `List α`\n* `List α` works well as a persistent data structure, when many copies of the\n  tail are shared. When the value is not shared, `Array α` will have better\n  performance because it can do destructive updates.\n</code>",
 "2":
 "<code>Array.push.{u} {α : Type u} (a : Array α) (v : α) : Array α</code><span class=\"sep\"></span><code class=\"docstring\">Push an element onto the end of an array. This is amortized O(1) because\n`Array α` is internally a dynamic array.\n</code>",
 "199":
 "<code>mapMono_mapIdxMono {I : Type} [SciLean.IndexType I] (x : Float^[I]) (f : Float → Float) (g : I → Float → Float) :\n  (x.mapMono f).mapIdxMono g = x.mapIdxMono fun i x =&gt; g i (f x)</code>",
 "198":
 "<code>SciLean.ArrayType.mapMono.{u_1, u_2, u_3} {Cont : Type u_1} {Idx : outParam (Type u_2)} {Elem : outParam (Type u_3)}\n  [SciLean.IndexType Idx] [SciLean.ArrayType Cont Idx Elem] (f : Elem → Elem) (cont : Cont) : Cont</code>",
 "197":
 "<code>SciLean.ArrayType.mapIdxMono.{u_1, u_2, u_3} {Cont : Type u_1} {Idx : outParam (Type u_2)} {Elem : outParam (Type u_3)}\n  [SciLean.IndexType Idx] [SciLean.ArrayType Cont Idx Elem] (f : Idx → Elem → Elem) (cont : Cont) : Cont</code>",
 "196":
 "<code>_root_.saxpy_naive {n : ℕ} (a : Float) (x y : Float^[n]) : Float^[n]</code>",
 "195": "<code>saxpy {n : ℕ} (a : Float) (x y : Float^[n]) : Float^[n]</code>",
 "194":
 "<code>mapMono_mapIdxMono {I : Type} [IndexType I] (x : Float^[I]) (f : Float → Float) (g : I → Float → Float) :\n  (x.mapMono f).mapIdxMono g = x.mapIdxMono fun i x =&gt; g i (f x)</code>",
 "193":
 "<code>SciLean.ArrayType.mapIdxMono.{u_1, u_2, u_3} {Cont : Type u_1} {Idx : outParam (Type u_2)} {Elem : outParam (Type u_3)}\n  [IndexType Idx] [ArrayType Cont Idx Elem] (f : Idx → Elem → Elem) (cont : Cont) : Cont</code>",
 "192":
 "<code>SMul.smul.{u, v} {M : Type u} {α : Type v} [self : SMul M α] : M → α → α</code><span class=\"sep\"></span><code class=\"docstring\">`a • b` computes the product of `a` and `b`. The meaning of this notation is type-dependent,\nbut it is intended to be used for left actions. </code>",
 "191":
 "<code>HSMul.hSMul.{u, v, w} {α : Type u} {β : Type v} {γ : outParam (Type w)} [self : HSMul α β γ] : α → β → γ</code><span class=\"sep\"></span><code class=\"docstring\">`a • b` computes the product of `a` and `b`.\nThe meaning of this notation is type-dependent, but it is intended to be used for left actions. </code>",
 "190":
 "<code>Add.add.{u} {α : Type u} [self : Add α] : α → α → α</code><span class=\"sep\"></span><code class=\"docstring\">`a + b` computes the sum of `a` and `b`. See `HAdd`. </code>",
 "19":
 "<code>SciLean.DataArrayN (α : Type) [pd : PlainDataType α] (ι : Type) [IndexType ι] : Type</code>",
 "189":
 "<code>_root_.saxpy {n : ℕ} (a : Float) (x y : Float^[n]) : Float^[n]</code>",
 "188":
 "<code>SciLean.ArrayType.mapMono.{u_1, u_2, u_3} {Cont : Type u_1} {Idx : outParam (Type u_2)} {Elem : outParam (Type u_3)}\n  [IndexType Idx] [ArrayType Cont Idx Elem] (f : Elem → Elem) (cont : Cont) : Cont</code>",
 "187": "<code>I → Float → Float</code>",
 "186":
 "<code>_root_.mapMono_mapIdxMono {I : Type} [IndexType I] (x : Float^[I]) (f : Float → Float) (g : I → Float → Float) :\n  (x.mapMono f).mapIdxMono g = x.mapIdxMono fun i x =&gt; g i (f x)</code>",
 "185":
 "<code class=\"docstring\">The `simp` tactic uses lemmas and hypotheses to simplify the main goal target or\nnon-dependent hypotheses. It has many variants:\n- `simp` simplifies the main goal target using lemmas tagged with the attribute `[simp]`.\n- `simp [h₁, h₂, ..., hₙ]` simplifies the main goal target using the lemmas tagged\n  with the attribute `[simp]` and the given `hᵢ`'s, where the `hᵢ`'s are expressions.\n  If an `hᵢ` is a defined constant `f`, then the equational lemmas associated with\n  `f` are used. This provides a convenient way to unfold `f`.\n- `simp [*]` simplifies the main goal target using the lemmas tagged with the\n  attribute `[simp]` and all hypotheses.\n- `simp only [h₁, h₂, ..., hₙ]` is like `simp [h₁, h₂, ..., hₙ]` but does not use `[simp]` lemmas.\n- `simp [-id₁, ..., -idₙ]` simplifies the main goal target using the lemmas tagged\n  with the attribute `[simp]`, but removes the ones named `idᵢ`.\n- `simp at h₁ h₂ ... hₙ` simplifies the hypotheses `h₁ : T₁` ... `hₙ : Tₙ`. If\n  the target or another hypothesis depends on `hᵢ`, a new simplified hypothesis\n  `hᵢ` is introduced, but the old one remains in the local context.\n- `simp at *` simplifies all the hypotheses and the target.\n- `simp [*] at *` simplifies target and all (propositional) hypotheses using the\n  other hypotheses.\n</code>",
 "184":
 "<code class=\"docstring\">Applies extensionality lemmas that are registered with the `@[ext]` attribute.\n* `ext pat*` applies extensionality theorems as much as possible,\n  using the patterns `pat*` to introduce the variables in extensionality theorems using `rintro`.\n  For example, the patterns are used to name the variables introduced by lemmas such as `funext`.\n* Without patterns,`ext` applies extensionality lemmas as much\n  as possible but introduces anonymous hypotheses whenever needed.\n* `ext pat* : n` applies ext theorems only up to depth `n`.\n\nThe `ext1 pat*` tactic is like `ext pat*` except that it only applies a single extensionality theorem.\n\nUnused patterns will generate warning.\nPatterns that don't match the variables will typically result in the introduction of anonymous hypotheses.\n</code>",
 "183": "<code>IndexType I</code>",
 "182":
 "<code>_root_.mapMono_mapMono {I : Type} [IndexType I] (x : Float^[I]) (f g : Float → Float) :\n  (x.mapMono f).mapMono g = x.mapMono fun x =&gt; g (f x)</code>",
 "181":
 "<code>add_zero.{u} {M : Type u} [AddZeroClass M] (a : M) : a + 0 = a</code>",
 "180": "<code>Lean.initFn._@.Lean.Meta.Tactic.Simp._hyg.123</code>",
 "18": "<code>fibonacci (n : ℕ) : DataArray UInt64</code>",
 "179":
 "<code class=\"docstring\">`set_option &lt;id&gt; &lt;value&gt;` sets the option `&lt;id&gt;` to `&lt;value&gt;`. Depending on the type of the option,\nthe value can be `true`, `false`, a string, or a numeral. Options are used to configure behavior of\nLean as well as user-defined extensions. The setting is active until the end of the current `section`\nor `namespace` or the end of the file.\nAuto-completion is available for `&lt;id&gt;` to list available options.\n\n`set_option &lt;id&gt; &lt;value&gt; in &lt;command&gt;` sets the option for just a single command:\n```\nset_option pp.all true in\n#check 1 + 1\n```\nSimilarly, `set_option &lt;id&gt; &lt;value&gt; in` can also be used inside terms and tactics to set an option\nonly in a single term or tactic.\n</code>",
 "178":
 "<code class=\"docstring\">`simp [thm]` performs simplification using `thm` and marked `@[simp]` lemmas.\nSee the `simp` tactic for more information. </code>",
 "177":
 "<code>rfl.{u} {α : Sort u} {a : α} : a = a</code><span class=\"sep\"></span><code class=\"docstring\">`rfl : a = a` is the unique constructor of the equality type. This is the\nsame as `Eq.refl` except that it takes `a` implicitly instead of explicitly.\n\nThis is a more powerful theorem than it may appear at first, because although\nthe statement of the theorem is `a = a`, Lean will allow anything that is\ndefinitionally equal to that type. So, for instance, `2 + 2 = 4` is proven in\nLean by `rfl`, because both sides are the same up to definitional equality.\n</code>",
 "176": "<code>OptimizingArrays.Nat.add_zero (n : ℕ) : n + 0 = n</code>",
 "175":
 "<code class=\"docstring\">Theorems tagged with the `simp` attribute are used by the simplifier\n(i.e., the `simp` tactic, and its variants) to simplify expressions occurring in your goals.\nWe call theorems tagged with the `simp` attribute \"simp theorems\" or \"simp lemmas\".\nLean maintains a database/index containing all active simp theorems.\nHere is an example of a simp theorem.\n```lean\n@[simp] theorem ne_eq (a b : α) : (a ≠ b) = Not (a = b) := rfl\n```\nThis simp theorem instructs the simplifier to replace instances of the term\n`a ≠ b` (e.g. `x + 0 ≠ y`) with `Not (a = b)` (e.g., `Not (x + 0 = y)`).\nThe simplifier applies simp theorems in one direction only:\nif `A = B` is a simp theorem, then `simp` replaces `A`s with `B`s,\nbut it doesn't replace `B`s with `A`s. Hence a simp theorem should have the\nproperty that its right-hand side is \"simpler\" than its left-hand side.\nIn particular, `=` and `↔` should not be viewed as symmetric operators in this situation.\nThe following would be a terrible simp theorem (if it were even allowed):\n```lean\n@[simp] lemma mul_right_inv_bad (a : G) : 1 = a * a⁻¹ := ...\n```\nReplacing 1 with a * a⁻¹ is not a sensible default direction to travel.\nEven worse would be a theorem that causes expressions to grow without bound,\ncausing simp to loop forever.\n\nBy default the simplifier applies `simp` theorems to an expression `e`\nafter its sub-expressions have been simplified.\nWe say it performs a bottom-up simplification.\nYou can instruct the simplifier to apply a theorem before its sub-expressions\nhave been simplified by using the modifier `↓`. Here is an example\n```lean\n@[simp↓] theorem not_and_eq (p q : Prop) : (¬ (p ∧ q)) = (¬p ∨ ¬q) :=\n```\n\nWhen multiple simp theorems are applicable, the simplifier uses the one with highest priority.\nThe equational theorems of function are applied at very low priority (100 and below).\nIf there are several with the same priority, it is uses the \"most recent one\". Example:\n```lean\n@[simp high] theorem cond_true (a b : α) : cond true a b = a := rfl\n@[simp low+1] theorem or_true (p : Prop) : (p ∨ True) = True :=\n  propext &lt;| Iff.intro (fun _ =&gt; trivial) (fun _ =&gt; Or.inr trivial)\n@[simp 100] theorem ite_self {d : Decidable c} (a : α) : ite c a a = a := by\n  cases d &lt;;&gt; rfl\n```\n</code>",
 "174":
 "<code>nnet :\n  Float^[8, 1, ↑(Set.Icc (-↑1) ↑1), ↑(Set.Icc (-↑1) ↑1)] ×\n      Float^[8, 28, 28] × Float^[30, 8, 14, 14] × Float^[30] × Float^[10, 30] × Float^[10] →\n    Float^[28, 28] → Float^[10]</code>",
 "173":
 "<code>softMax {I : Type} [SciLean.IndexType I] (r : Float) (x : Float^[I]) : Float^[I]</code>",
 "172":
 "<code>dense {I : Type} [SciLean.IndexType I] (n : ℕ) (A : Float^[n, I]) (b : Float^[n]) (x : Float^[I]) : Float^[n]</code>",
 "171":
 "<code>avgPool2d {n₁ n₂ : ℕ} {I : Type} [SciLean.IndexType I] (x : Float^[I, n₁, n₂]) {m₁ m₂ : ℕ}\n  (h₁ : m₁ = n₁ / 2 := by infer_var ) (h₂ : m₂ = n₂ / 2 := by infer_var ) : Float^[I, m₁, m₂]</code>",
 "170":
 "<code>SciLean.DataArrayN.mapMono {I X : Type} [SciLean.IndexType I] [SciLean.PlainDataType X] (x : X^[I]) (f : X → X) : X^[I]</code>",
 "17":
 "<code>SciLean.DataArray.push {α : Type} [pd : PlainDataType α] (arr : DataArray α) (val : α) (k : ℕ := 1) : DataArray α</code>",
 "169":
 "<code>conv2d {n m : ℕ} (k : ℕ) (J : Type) {I : Type} [SciLean.IndexType I] [SciLean.IndexType J] [DecidableEq J]\n  (w : Float^[J, I, ↑(Set.Icc (-↑k) ↑k), ↑(Set.Icc (-↑k) ↑k)]) (b : Float^[J, n, m]) (x : Float^[I, n, m]) :\n  Float^[J, n, m]</code>",
 "168":
 "<code>Neg.neg.{u} {α : Type u} [self : Neg α] : α → α</code><span class=\"sep\"></span><code class=\"docstring\">`-a` computes the negative or opposite of `a`.\nThe meaning of this notation is type-dependent. </code>",
 "167":
 "<code>Set.Icc.{u_1} {α : Type u_1} [Preorder α] (a b : α) : Set α</code><span class=\"sep\"></span><code class=\"docstring\">Left-closed right-closed interval </code>",
 "166":
 "<code>Float^[8, 1, ↑(Set.Icc (-↑1) ↑1), ↑(Set.Icc (-↑1) ↑1)] ×\n  Float^[8, 28, 28] × Float^[30, 8, 14, 14] × Float^[30] × Float^[10, 30] × Float^[10]</code>",
 "165": "<code>Float^[28, 28]</code>",
 "164": "<code>Float^[10]</code>",
 "163": "<code>Float^[10, 30]</code>",
 "162": "<code>Float^[30]</code>",
 "161": "<code>Float^[30, 8, 14, 14]</code>",
 "160": "<code>Float^[8, 28, 28]</code>",
 "16":
 "<code>SciLean.DataArray.mkEmpty {α : Type} [pd : PlainDataType α] (capacity : ℕ) : DataArray α</code>",
 "159": "<code>Float^[8, 1, ↑(Set.Icc (-↑1) ↑1), ↑(Set.Icc (-↑1) ↑1)]</code>",
 "158":
 "<code>_root_.nnet :\n  Float^[8, 1, ↑(Set.Icc (-↑1) ↑1), ↑(Set.Icc (-↑1) ↑1)] ×\n      Float^[8, 28, 28] × Float^[30, 8, 14, 14] × Float^[30] × Float^[10, 30] × Float^[10] →\n    Float^[28, 28] → Float^[10]</code>",
 "157":
 "<code>_root_.dense {I : Type} [IndexType I] (n : ℕ) (A : Float^[n, I]) (b : Float^[n]) (x : Float^[I]) : Float^[n]</code>",
 "156": "<code>Fin m₂</code>",
 "155": "<code>Fin m₁</code>",
 "154": "<code>autoParam (m₂ = n₂ / 2) _auto✝</code>",
 "153": "<code>autoParam (m₁ = n₁ / 2) _auto✝</code>",
 "152": "<code>Float^[I, n₁, n₂]</code>",
 "151":
 "<code>_root_.avgPool2d {n₁ n₂ : ℕ} {I : Type} [IndexType I] (x : Float^[I, n₁, n₂]) {m₁ m₂ : ℕ}\n  (h₁ : m₁ = n₁ / 2 := by infer_var ) (h₂ : m₂ = n₂ / 2 := by infer_var ) : Float^[I, m₁, m₂]</code>",
 "150": "<code>_auto✝ : Lean.Syntax</code>",
 "15": "<code>DataArray UInt64</code>",
 "149":
 "<code>autoParam.{u} (α : Sort u) (tactic : Lean.Syntax) : Sort u</code><span class=\"sep\"></span><code class=\"docstring\">Gadget for automatic parameter support. This is similar to the `optParam` gadget, but it uses\nthe given tactic.\nLike `optParam`, this gadget only affects elaboration.\nFor example, the tactic will *not* be invoked during type class resolution. </code>",
 "148": "<code>autoParam (m = n / 2) _auto✝</code>",
 "147":
 "<code>_root_.avgPool {n : ℕ} (x : Float^[n]) {m : ℕ} (h : m = n / 2 := by infer_var ) : Float^[m]</code>",
 "146": "<code>Fin (2 * n)</code>",
 "145": "<code>Float^[2 * n]</code>",
 "144": "<code>_root_.avgPool {n : ℕ} (x : Float^[2 * n]) : Float^[n]</code>",
 "143": "<code>i : Fin 10</code>",
 "142": "<code>_root_.i : Fin 10</code>",
 "141":
 "<code>HAdd.hAdd.{u, v, w} {α : Type u} {β : Type v} {γ : outParam (Type w)} [self : HAdd α β γ] : α → β → γ</code><span class=\"sep\"></span><code class=\"docstring\">`a + b` computes the sum of `a` and `b`.\nThe meaning of this notation is type-dependent. </code>",
 "140":
 "<code class=\"docstring\">The `omega` tactic, for resolving integer and natural linear arithmetic problems.\n\nIt is not yet a full decision procedure (no \"dark\" or \"grey\" shadows),\nbut should be effective on many problems.\n\nWe handle hypotheses of the form `x = y`, `x &lt; y`, `x ≤ y`, and `k ∣ x` for `x y` in `Nat` or `Int`\n(and `k` a literal), along with negations of these statements.\n\nWe decompose the sides of the inequalities as linear combinations of atoms.\n\nIf we encounter `x / k` or `x % k` for literal integers `k` we introduce new auxiliary variables\nand the relevant inequalities.\n\nOn the first pass, we do not perform case splits on natural subtraction.\nIf `omega` fails, we recursively perform a case split on\na natural subtraction appearing in a hypothesis, and try again.\n\nThe options\n```\nomega (config :=\n  { splitDisjunctions := true, splitNatSub := true, splitNatAbs := true, splitMinMax := true })\n```\ncan be used to:\n* `splitDisjunctions`: split any disjunctions found in the context,\n  if the problem is not otherwise solvable.\n* `splitNatSub`: for each appearance of `((a - b : Nat) : Int)`, split on `a ≤ b` if necessary.\n* `splitNatAbs`: for each appearance of `Int.natAbs a`, split on `0 ≤ a` if necessary.\n* `splitMinMax`: for each occurrence of `min a b`, split on `min a b = a ∨ min a b = b`\nCurrently, all of these are on by default.\n</code>",
 "14": "<code>_root_.fibonacci (n : ℕ) : DataArray UInt64</code>",
 "139":
 "<code>LT.lt.{u} {α : Type u} [self : LT α] : α → α → Prop</code><span class=\"sep\"></span><code class=\"docstring\">The less-than relation: `x &lt; y` </code>",
 "138":
 "<code>HMul.hMul.{u, v, w} {α : Type u} {β : Type v} {γ : outParam (Type w)} [self : HMul α β γ] : α → β → γ</code><span class=\"sep\"></span><code class=\"docstring\">`a * b` computes the product of `a` and `b`.\nThe meaning of this notation is type-dependent. </code>",
 "137":
 "<code>HDiv.hDiv.{u, v, w} {α : Type u} {β : Type v} {γ : outParam (Type w)} [self : HDiv α β γ] : α → β → γ</code><span class=\"sep\"></span><code class=\"docstring\">`a / b` computes the result of dividing `a` by `b`.\nThe meaning of this notation is type-dependent.\n* For most types like `Nat`, `Int`, `Rat`, `Real`, `a / 0` is defined to be `0`.\n* For `Nat`, `a / b` rounds downwards.\n* For `Int`, `a / b` rounds downwards if `b` is positive or upwards if `b` is negative.\n  It is implemented as `Int.ediv`, the unique function satisfiying\n  `a % b + b * (a / b) = a` and `0 ≤ a % b &lt; natAbs b` for `b ≠ 0`.\n  Other rounding conventions are available using the functions\n  `Int.fdiv` (floor rounding) and `Int.div` (truncation rounding).\n* For `Float`, `a / 0` follows the IEEE 754 semantics for division,\n  usually resulting in `inf` or `nan`. </code>",
 "136": "<code>Fin (n / 2)</code>",
 "135": "<code>_root_.avgPool {n : ℕ} (x : Float^[n]) : Float^[n / 2]</code>",
 "134": "<code>J</code>",
 "133": "<code>Float^[I, n, m]</code>",
 "132": "<code>Float^[J, n, m]</code>",
 "131": "<code>Float^[J, I, ↑(Set.Icc (-↑k) ↑k), ↑(Set.Icc (-↑k) ↑k)]</code>",
 "130":
 "<code>_root_.conv2d {n m : ℕ} (k : ℕ) (J : Type) {I : Type} [IndexType I] [IndexType J] [DecidableEq J]\n  (w : Float^[J, I, ↑(Set.Icc (-↑k) ↑k), ↑(Set.Icc (-↑k) ↑k)]) (b : Float^[J, n, m]) (x : Float^[I, n, m]) :\n  Float^[J, n, m]</code>",
 "13":
 "<code class=\"docstring\">Makes names from other namespaces visible without writing the namespace prefix.\n\nNames that are made available with `open` are visible within the current `section` or `namespace`\nblock. This makes referring to (type) definitions and theorems easier, but note that it can also\nmake [scoped instances], notations, and attributes from a different namespace available.\n\nThe `open` command can be used in a few different ways:\n\n* `open Some.Namespace.Path1 Some.Namespace.Path2` makes all non-protected names in\n  `Some.Namespace.Path1` and `Some.Namespace.Path2` available without the prefix, so that\n  `Some.Namespace.Path1.x` and `Some.Namespace.Path2.y` can be referred to by writing only `x` and\n  `y`.\n\n* `open Some.Namespace.Path hiding def1 def2` opens all non-protected names in `Some.Namespace.Path`\n  except `def1` and `def2`.\n\n* `open Some.Namespace.Path (def1 def2)` only makes `Some.Namespace.Path.def1` and\n  `Some.Namespace.Path.def2` available without the full prefix, so `Some.Namespace.Path.def3` would\n  be unaffected.\n\n  This works even if `def1` and `def2` are `protected`.\n\n* `open Some.Namespace.Path renaming def1 → def1', def2 → def2'` same as `open Some.Namespace.Path\n  (def1 def2)` but `def1`/`def2`'s names are changed to `def1'`/`def2'`.\n\n  This works even if `def1` and `def2` are `protected`.\n\n* `open scoped Some.Namespace.Path1 Some.Namespace.Path2` **only** opens [scoped instances],\n  notations, and attributes from `Namespace1` and `Namespace2`; it does **not** make any other name\n  available.\n\n* `open &lt;any of the open shapes above&gt; in` makes the names `open`-ed visible only in the next\n  command or expression.\n\n[scoped instance]: https://lean-lang.org/theorem_proving_in_lean4/type_classes.html#scoped-instances\n(Scoped instances in Theorem Proving in Lean)\n\n\n## Examples\n\n```lean\n/-- SKI combinators https://en.wikipedia.org/wiki/SKI_combinator_calculus -/\nnamespace Combinator.Calculus\n  def I (a : α) : α := a\n  def K (a : α) : β → α := fun _ =&gt; a\n  def S (x : α → β → γ) (y : α → β) (z : α) : γ := x z (y z)\nend Combinator.Calculus\n\nsection\n  -- open everything under `Combinator.Calculus`, *i.e.* `I`, `K` and `S`,\n  -- until the section ends\n  open Combinator.Calculus\n\n  theorem SKx_eq_K : S K x = I := rfl\nend\n\n-- open everything under `Combinator.Calculus` only for the next command (the next `theorem`, here)\nopen Combinator.Calculus in\ntheorem SKx_eq_K' : S K x = I := rfl\n\nsection\n  -- open only `S` and `K` under `Combinator.Calculus`\n  open Combinator.Calculus (S K)\n\n  theorem SKxy_eq_y : S K x y = y := rfl\n\n  -- `I` is not in scope, we have to use its full path\n  theorem SKxy_eq_Iy : S K x y = Combinator.Calculus.I y := rfl\nend\n\nsection\n  open Combinator.Calculus\n    renaming\n      I → identity,\n      K → konstant\n\n  #check identity\n  #check konstant\nend\n\nsection\n  open Combinator.Calculus\n    hiding S\n\n  #check I\n  #check K\nend\n\nsection\n  namespace Demo\n    inductive MyType\n    | val\n\n    namespace N1\n      scoped infix:68 \" ≋ \" =&gt; BEq.beq\n\n      scoped instance : BEq MyType where\n        beq _ _ := true\n\n      def Alias := MyType\n    end N1\n  end Demo\n\n  -- bring `≋` and the instance in scope, but not `Alias`\n  open scoped Demo.N1\n\n  #check Demo.MyType.val == Demo.MyType.val\n  #check Demo.MyType.val ≋ Demo.MyType.val\n  -- #check Alias -- unknown identifier 'Alias'\nend\n```\n</code>",
 "129": "<code>Float^[↑(Set.Icc (-↑k) ↑k), ↑(Set.Icc (-↑k) ↑k)]</code>",
 "128":
 "<code>_root_.conv2d {n m k : ℕ} (w : Float^[↑(Set.Icc (-↑k) ↑k), ↑(Set.Icc (-↑k) ↑k)]) (x : Float^[n, m]) : Float^[n, m]</code>",
 "127": "<code>↑(Set.Icc (-↑k) ↑k)</code>",
 "126": "<code>Float^[↑(Set.Icc (-↑k) ↑k)]</code>",
 "125":
 "<code>_root_.conv1d {n k : ℕ} (w : Float^[↑(Set.Icc (-↑k) ↑k)]) (x : Float^[n]) : Float^[n]</code>",
 "124":
 "<code>((Int.ofNat ↑i + j) % ↑n).toNat &lt; n</code><span class=\"sep\"></span><code class=\"docstring\">If `i : Fin n`, then `i.2` is a proof that `i.1 &lt; n`. </code>",
 "123":
 "<code>Int.toNat : ℤ → ℕ</code><span class=\"sep\"></span><code class=\"docstring\">Turns an integer into a natural number, negative numbers become\n`0`.\n\n```\n#eval (7 : Int).toNat -- 7\n#eval (0 : Int).toNat -- 0\n#eval (-7 : Int).toNat -- 0\n```\n</code>",
 "122":
 "<code>Int.ofNat : ℕ → ℤ</code><span class=\"sep\"></span><code class=\"docstring\">A natural number is an integer (`0` to `∞`). </code>",
 "121":
 "<code>ℕ</code><span class=\"sep\"></span><code class=\"docstring\">If `i : Fin n`, then `i.val : ℕ` is the described number. It can also be\nwritten as `i.1` or just `i` when the target type is known. </code>",
 "120": "<code>ℤ</code>",
 "12":
 "<code>UInt64 : Type</code><span class=\"sep\"></span><code class=\"docstring\">The type of unsigned 64-bit integers. This type has special support in the\ncompiler to make it actually 64 bits rather than wrapping a `Nat`.\n</code>",
 "119": "<code>Fin.shift {n : ℕ} (i : Fin n) (j : ℤ) : Fin n</code>",
 "118": "<code>Fin k</code>",
 "117": "<code>Float^[k]</code>",
 "116":
 "<code>_root_.conv1d {n k : ℕ} (x : Float^[n]) (w : Float^[k]) : Float^[n]</code>",
 "115": "<code>Float^[n, n]</code>",
 "114": "<code>_root_.trace {n : ℕ} (A : Float^[n, n]) : Float</code>",
 "113":
 "<code>_root_.matMul {n m : ℕ} (A : Float^[n, m]) (x : Float^[m]) : Float^[n]</code>",
 "112": "<code>B : Float^[2, 2]</code>",
 "111": "<code>x : Float^[4]</code>",
 "110": "<code>Fin 4</code>",
 "11":
 "<code>SciLean.DataArray (α : Type) [pd : PlainDataType α] : Type</code>",
 "109": "<code>_root_.B : Float^[2, 2]</code>",
 "108": "<code>_root_.x : Float^[4]</code>",
 "107":
 "<code>SciLean.Scalar.exp.{u_1, u_2} {R : outParam (Type u_1)} {K : semiOutParam (Type u_2)} [self : Scalar R K] (x : K) : K</code>",
 "106":
 "<code>Max.max.{u} {α : Type u} [self : Max α] : α → α → α</code><span class=\"sep\"></span><code class=\"docstring\">The maximum operation: `max x y`. </code>",
 "105":
 "<code>SciLean.DataArrayN.reduce {I X : Type} [IndexType I] [PlainDataType X] [Inhabited X] (x : X^[I]) (f : X → X → X) : X</code>",
 "104":
 "<code>_root_.softMax {I : Type} [IndexType I] (r : Float) (x : Float^[I]) : Float^[I]</code>",
 "103":
 "<code>Min.min.{u} {α : Type u} [self : Min α] : α → α → α</code><span class=\"sep\"></span><code class=\"docstring\">The minimum operation: `min x y`. </code>",
 "102":
 "<code>SciLean.DataArrayN.reduce {I X : Type} [SciLean.IndexType I] [SciLean.PlainDataType X] [Inhabited X] (x : X^[I])\n  (f : X → X → X) : X</code>",
 "101":
 "<code>SciLean.DataArrayN.foldl {I X : Type} [SciLean.IndexType I] [SciLean.PlainDataType X] (x : X^[I]) (op : X → X → X)\n  (init : X) : X</code>",
 "100":
 "<code>Inhabited.{u} (α : Sort u) : Sort (max 1 u)</code><span class=\"sep\"></span><code class=\"docstring\">`Inhabited α` is a typeclass that says that `α` has a designated element,\ncalled `(default : α)`. This is sometimes referred to as a \"pointed type\".\n\nThis class is used by functions that need to return a value of the type\nwhen called \"out of domain\". For example, `Array.get! arr i : α` returns\na value of type `α` when `arr : Array α`, but if `i` is not in range of\nthe array, it reports a panic message, but this does not halt the program,\nso it must still return a value of type `α` (and in fact this is required\nfor logical consistency), so in this case it returns `default`.\n</code>",
 "10": "<code>fibonacci (n : ℕ) : Array ℕ</code>",
 "1":
 "<code>Array.mkEmpty.{u} {α : Type u} (c : ℕ) : Array α</code><span class=\"sep\"></span><code class=\"docstring\">Construct a new empty array with initial capacity `c`. </code>",
 "0":
 "<code>Array.{u} (α : Type u) : Type u</code><span class=\"sep\"></span><code class=\"docstring\">`Array α` is the type of [dynamic arrays](https://en.wikipedia.org/wiki/Dynamic_array)\nwith elements from `α`. This type has special support in the runtime.\n\nAn array has a size and a capacity; the size is `Array.size` but the capacity\nis not observable from Lean code. Arrays perform best when unshared; as long\nas they are used \"linearly\" all updates will be performed destructively on the\narray, so it has comparable performance to mutable arrays in imperative\nprogramming languages.\n\nFrom the point of view of proofs `Array α` is just a wrapper around `List α`.\n</code>"}