{"99": "<code>x : Float^[4]</code>",
 "98":
 "<code>SciLean.Scalar.exp.{u_1, u_2} {R : outParam (Type u_1)} {K : Type u_2} [self : Scalar R K] (x : K) : K</code>",
 "97":
 "<code>Max.max.{u} {α : Type u} [self : Max α] : α → α → α</code><span class=\"sep\"></span><code class=\"docstring\">The maximum operation: `max x y`. </code>",
 "96":
 "<code>softMax {I : Type} [IndexType I] (r : Float) (x : Float^[I]) : Float^[I]</code>",
 "95":
 "<code>Min.min.{u} {α : Type u} [self : Min α] : α → α → α</code><span class=\"sep\"></span><code class=\"docstring\">The minimum operation: `min x y`. </code>",
 "94":
 "<code>SciLean.DataArrayN.reduce.{u_1, u_2} {X : Type u_1} [PlainDataType X] {I : Type u_2} [IndexType I] [Inhabited X]\n  (op : X → X → X) (xs : X^[I]) : X</code><span class=\"sep\"></span><code class=\"docstring\">Reduce elements of `xs : X^[I]` using `op : X → X → X`.\n\nIt is just and abbreviation for a call to `IndexType.reduce` which does reduction over the index\ntype `I`. </code>",
 "93":
 "<code>SciLean.DataArrayN.foldl.{u_1, u_2, u_3} {X : Type u_1} [PlainDataType X] {I : Type u_2} [IndexType I] {α : Type u_3}\n  (op : α → X → α) (init : α) (xs : X^[I]) : α</code><span class=\"sep\"></span><code class=\"docstring\">Fold elements of `xs : X^[I]` using `op : α → X → α`.\n\nIt is just and abbreviation for a call to `IndexType.foldl` which runs a fold over the index\ntype `I`. </code>",
 "92":
 "<code>SciLean.DataArrayN.mapIdxMono.{u_1, u_2} {X : Type u_1} [PlainDataType X] {I : Type u_2} [IndexType I] (f : I → X → X)\n  (xs : X^[I]) : X^[I]</code><span class=\"sep\"></span><code class=\"docstring\">Transform all elements of `xs^[I]` using `f : I → X → X`. </code>",
 "91": "<code>Float^[3]</code>",
 "90":
 "<code>SciLean.Scalar.sqrt.{u_1, u_2} {R : outParam (Type u_1)} {K : Type u_2} [self : Scalar R K] (x : K) : K</code>",
 "9":
 "<code class=\"docstring\">`for x in e do s`  iterates over `e` assuming `e`'s type has an instance of the `ForIn` typeclass.\n`break` and `continue` are supported inside `for` loops.\n`for x in e, x2 in e2, ... do s` iterates of the given collections in parallel,\nuntil at least one of them is exhausted.\nThe types of `e2` etc. must implement the `ToStream` typeclass.\n</code>",
 "89":
 "<code>SciLean.DataArrayN.mapMono.{u_1, u_2} {X : Type u_1} [PlainDataType X] {I : Type u_2} [IndexType I] (f : X → X)\n  (xs : X^[I]) : X^[I]</code><span class=\"sep\"></span><code class=\"docstring\">Transform all elements of `xs^[I]` using `f : X → X`. </code>",
 "88": "<code>Float → Float</code>",
 "87":
 "<code>map {I : Type} [IndexType I] (x : Float^[I]) (f : Float → Float) : Float^[I]</code>",
 "86": "<code>I</code>",
 "85":
 "<code>covariance {n : ℕ} {I : Type} [IndexType I] (x : Float^[I]^[n]) : Float^[I, I]</code>",
 "84": "<code>Float^[I]^[n]</code>",
 "83":
 "<code>mean {n : ℕ} {I : Type} [IndexType I] (x : Float^[I]^[n]) : Float^[I]</code>",
 "82":
 "<code>DecidableEq.{u} (α : Sort u) : Sort (max 1 u)</code><span class=\"sep\"></span><code class=\"docstring\">Asserts that `α` has decidable equality, that is, `a = b` is decidable\nfor all `a b : α`. See `Decidable`.\n</code>",
 "81":
 "<code class=\"docstring\">`let` is used to declare a local definition. Example:\n```\nlet x := 1\nlet y := x + 1\nx + y\n```\nSince functions are first class citizens in Lean, you can use `let` to declare\nlocal functions too.\n```\nlet double := fun x =&gt; 2*x\ndouble (double 3)\n```\nFor recursive definitions, you should use `let rec`.\nYou can also perform pattern matching using `let`. For example,\nassume `p` has type `Nat × Nat`, then you can write\n```\nlet (x, y) := p\nx + y\n```\n</code>",
 "80": "<code>variance {n : ℕ} (x : Float^[n]) : Float</code>",
 "8": "<code>instOfScientificFloat</code>",
 "79": "<code>Nat.toFloat (n : ℕ) : Float</code>",
 "78": "<code>mean {n : ℕ} (x : Float^[n]) : Float</code>",
 "77": "<code>Type u_17</code>",
 "76": "<code>Type u_16</code>",
 "75": "<code>Type u_15</code>",
 "74":
 "<code class=\"docstring\">The `sorry` term is a temporary placeholder for a missing proof or value.\n\nThe syntax is intended for stubbing-out incomplete parts of a value or proof while still having a syntactically correct skeleton.\nLean will give a warning whenever a declaration uses `sorry`, so you aren't likely to miss it,\nbut you can double check if a declaration depends on `sorry` by looking for `sorryAx` in the output\nof the `#print axioms my_thm` command, the axiom used by the implementation of `sorry`.\n\n\"Go to definition\" on `sorry` in the Infoview will go to the source position where it was introduced, if such information is available.\n\nEach `sorry` is guaranteed to be unique, so for example the following fails:\n```lean\nexample : (sorry : Nat) = sorry := rfl -- fails\n```\n\nSee also the `sorry` tactic, which is short for `exact sorry`.\n</code>",
 "73": "<code>Float^[I]</code>",
 "72": "<code>Type u_11</code>",
 "71": "<code>Type u_8</code>",
 "70":
 "<code class=\"docstring\">`decide` attempts to prove the main goal (with target type `p`) by synthesizing an instance of `Decidable p`\nand then reducing that instance to evaluate the truth value of `p`.\nIf it reduces to `isTrue h`, then `h` is a proof of `p` that closes the goal.\n\nThe target is not allowed to contain local variables or metavariables.\nIf there are local variables, you can first try using the `revert` tactic with these local variables to move them into the target,\nor you can use the `+revert` option, described below.\n\nOptions:\n- `decide +revert` begins by reverting local variables that the target depends on,\n  after cleaning up the local context of irrelevant variables.\n  A variable is *relevant* if it appears in the target, if it appears in a relevant variable,\n  or if it is a proposition that refers to a relevant variable.\n- `decide +kernel` uses kernel for reduction instead of the elaborator.\n  It has two key properties: (1) since it uses the kernel, it ignores transparency and can unfold everything,\n  and (2) it reduces the `Decidable` instance only once instead of twice.\n- `decide +native` uses the native code compiler (`#eval`) to evaluate the `Decidable` instance,\n  admitting the result via the `Lean.ofReduceBool` axiom.\n  This can be significantly more efficient than using reduction, but it is at the cost of increasing the size\n  of the trusted code base.\n  Namely, it depends on the correctness of the Lean compiler and all definitions with an `@[implemented_by]` attribute.\n  Like with `+kernel`, the `Decidable` instance is evaluated only once.\n\nLimitation: In the default mode or `+kernel` mode, since `decide` uses reduction to evaluate the term,\n`Decidable` instances defined by well-founded recursion might not work because evaluating them requires reducing proofs.\nReduction can also get stuck on `Decidable` instances with `Eq.rec` terms.\nThese can appear in instances defined using tactics (such as `rw` and `simp`).\nTo avoid this, create such instances using definitions such as `decidable_of_iff` instead.\n\n## Examples\n\nProving inequalities:\n```lean\nexample : 2 + 2 ≠ 5 := by decide\n```\n\nTrying to prove a false proposition:\n```lean\nexample : 1 ≠ 1 := by decide\n/-\ntactic 'decide' proved that the proposition\n  1 ≠ 1\nis false\n-/\n```\n\nTrying to prove a proposition whose `Decidable` instance fails to reduce\n```lean\nopaque unknownProp : Prop\n\nopen scoped Classical in\nexample : unknownProp := by decide\n/-\ntactic 'decide' failed for proposition\n  unknownProp\nsince its 'Decidable' instance reduced to\n  Classical.choice ⋯\nrather than to the 'isTrue' constructor.\n-/\n```\n\n## Properties and relations\n\nFor equality goals for types with decidable equality, usually `rfl` can be used in place of `decide`.\n```lean\nexample : 1 + 1 = 2 := by decide\nexample : 1 + 1 = 2 := by rfl\n```\n</code>",
 "7": "<code>Array ℕ</code>",
 "69":
 "<code>Eq.{u_1} {α : Sort u_1} : α → α → Prop</code><span class=\"sep\"></span><code class=\"docstring\">The equality relation. It has one introduction rule, `Eq.refl`.\nWe use `a = b` as notation for `Eq a b`.\nA fundamental property of equality is that it is an equivalence relation.\n```\nvariable (α : Type) (a b c d : α)\nvariable (hab : a = b) (hcb : c = b) (hcd : c = d)\n\nexample : a = d :=\n  Eq.trans (Eq.trans hab (Eq.symm hcb)) hcd\n```\nEquality is much more than an equivalence relation, however. It has the important property that every assertion\nrespects the equivalence, in the sense that we can substitute equal expressions without changing the truth value.\nThat is, given `h1 : a = b` and `h2 : p a`, we can construct a proof for `p b` using substitution: `Eq.subst h1 h2`.\nExample:\n```\nexample (α : Type) (a b : α) (p : α → Prop)\n        (h1 : a = b) (h2 : p a) : p b :=\n  Eq.subst h1 h2\n\nexample (α : Type) (a b : α) (p : α → Prop)\n    (h1 : a = b) (h2 : p a) : p b :=\n  h1 ▸ h2\n```\nThe triangle in the second presentation is a macro built on top of `Eq.subst` and `Eq.symm`, and you can enter it by typing `\\t`.\nFor more information: [Equality](https://lean-lang.org/theorem_proving_in_lean4/quantifiers_and_equality.html#equality)\n</code>",
 "68":
 "<code>Prod.{u, v} (α : Type u) (β : Type v) : Type (max u v)</code><span class=\"sep\"></span><code class=\"docstring\">Product type (aka pair). You can use `α × β` as notation for `Prod α β`.\nGiven `a : α` and `b : β`, `Prod.mk a b : Prod α β`. You can use `(a, b)`\nas notation for `Prod.mk a b`. Moreover, `(a, b, c)` is notation for\n`Prod.mk a (Prod.mk b c)`.\nGiven `p : Prod α β`, `p.1 : α` and `p.2 : β`. They are short for `Prod.fst p`\nand `Prod.snd p` respectively. You can also write `p.fst` and `p.snd`.\nFor more information: [Constructors with Arguments](https://lean-lang.org/theorem_proving_in_lean4/inductive_types.html?highlight=Prod#constructors-with-arguments)\n</code>",
 "67":
 "<code class=\"docstring\">`by tac` constructs a term of the expected type by running the tactic(s) `tac`. </code>",
 "66":
 "<code>SciLean.DataArrayN.reshape.{u_1, u_3, u_4} {α : Type u_1} [pd : PlainDataType α] {ι : Type u_4} [IndexType ι]\n  (x : α^[ι]) (κ : Type u_3) [IndexType κ] (hs : size κ = size ι) : α^[κ]</code>",
 "65":
 "<code class=\"docstring\">Same as `sorry` but makes sure that the term is of type `Prop`.\n\n`sorry_proof` is very useful when writing programs such that you do not accidantelly add `sorry`\nwhich would prevent compiler from generating executable code. </code>",
 "64": "<code>size (Fin n × Fin m) = A.size</code>",
 "63": "<code>DataArray Float</code>",
 "62":
 "<code>SciLean.DataArray.reserve.{u_1} {α : Type u_1} [pd : PlainDataType α] (arr : DataArray α) (capacity : ℕ) : DataArray α</code><span class=\"sep\"></span><code class=\"docstring\">Makes sure that `arr` fits at least `n` elements of `α` </code>",
 "61":
 "<code>Inhabited.default.{u} {α : Sort u} [self : Inhabited α] : α</code><span class=\"sep\"></span><code class=\"docstring\">`default` is a function that produces a \"default\" element of any\n`Inhabited` type. This element does not have any particular specified\nproperties, but it is often an all-zeroes value. </code>",
 "60": "<code>DataArray Float</code>",
 "6": "<code>Id.run.{u_1} {α : Type u_1} (x : Id α) : α</code>",
 "59":
 "<code>outerProduct'' {n m : ℕ} (x : Float^[n]) (y : Float^[m]) : Float^[n, m]</code>",
 "58": "<code>SciLean.fullRange.{u} (I : Type u) : IndexType.Iterator I</code>",
 "57": "<code>Float^[n, m]</code>",
 "56":
 "<code>outerProduct {n m : ℕ} (x : Float^[n]) (y : Float^[m]) : Float^[n, m]</code>",
 "55": "<code>Fin m</code>",
 "54": "<code>Float^[m]</code>",
 "53":
 "<code>outerProduct {m n : ℕ} (x : Float^[m]) (y : Float^[n]) : Float^[m, n]</code>",
 "52": "<code>Fin 10</code>",
 "51":
 "<code>Fin (n : ℕ) : Type</code><span class=\"sep\"></span><code class=\"docstring\">`Fin n` is a natural number `i` with the constraint that `0 ≤ i &lt; n`.\nIt is the \"canonical type with `n` elements\".\n</code>",
 "50": "<code>Fin 10 → Float</code>",
 "5":
 "<code>Nat : Type</code><span class=\"sep\"></span><code class=\"docstring\">The type of natural numbers, starting at zero. It is defined as an\ninductive type freely generated by \"zero is a natural number\" and\n\"the successor of a natural number is a natural number\".\n\nYou can prove a theorem `P n` about `n : Nat` by `induction n`, which will\nexpect a proof of the theorem for `P 0`, and a proof of `P (succ i)` assuming\na proof of `P i`. The same method also works to define functions by recursion\non natural numbers: induction and recursion are two expressions of the same\noperation from Lean's point of view.\n\n```\nopen Nat\nexample (n : Nat) : n &lt; succ n := by\n  induction n with\n  | zero =&gt;\n    show 0 &lt; 1\n    decide\n  | succ i ih =&gt; -- ih : i &lt; succ i\n    show succ i &lt; succ (succ i)\n    exact Nat.succ_lt_succ ih\n```\n\nThis type is special-cased by both the kernel and the compiler:\n* The type of expressions contains \"`Nat` literals\" as a primitive constructor,\n  and the kernel knows how to reduce zero/succ expressions to nat literals.\n* If implemented naively, this type would represent a numeral `n` in unary as a\n  linked list with `n` links, which is horribly inefficient. Instead, the\n  runtime itself has a special representation for `Nat` which stores numbers up\n  to 2^63 directly and larger numbers use an arbitrary precision \"bignum\"\n  library (usually [GMP](https://gmplib.org/)).\n</code>",
 "49":
 "<code class=\"docstring\">Declares one or more typed variables, or modifies whether already-declared variables are\n  implicit.\n\nIntroduces variables that can be used in definitions within the same `namespace` or `section` block.\nWhen a definition mentions a variable, Lean will add it as an argument of the definition. This is\nuseful in particular when writing many definitions that have parameters in common (see below for an\nexample).\n\nVariable declarations have the same flexibility as regular function parameters. In particular they\ncan be [explicit, implicit][binder docs], or [instance implicit][tpil classes] (in which case they\ncan be anonymous). This can be changed, for instance one can turn explicit variable `x` into an\nimplicit one with `variable {x}`. Note that currently, you should avoid changing how variables are\nbound and declare new variables at the same time; see [issue 2789] for more on this topic.\n\nIn *theorem bodies* (i.e. proofs), variables are not included based on usage in order to ensure that\nchanges to the proof cannot change the statement of the overall theorem. Instead, variables are only\navailable to the proof if they have been mentioned in the theorem header or in an `include` command\nor are instance implicit and depend only on such variables.\n\nSee [*Variables and Sections* from Theorem Proving in Lean][tpil vars] for a more detailed\ndiscussion.\n\n[tpil vars]:\nhttps://lean-lang.org/theorem_proving_in_lean4/dependent_type_theory.html#variables-and-sections\n(Variables and Sections on Theorem Proving in Lean) [tpil classes]:\nhttps://lean-lang.org/theorem_proving_in_lean4/type_classes.html (Type classes on Theorem Proving in\nLean) [binder docs]:\nhttps://leanprover-community.github.io/mathlib4_docs/Lean/Expr.html#Lean.BinderInfo (Documentation\nfor the BinderInfo type) [issue 2789]: https://github.com/leanprover/lean4/issues/2789 (Issue 2789\non github)\n\n## Examples\n\n```lean\nsection\n  variable\n    {α : Type u}      -- implicit\n    (a : α)           -- explicit\n    [instBEq : BEq α] -- instance implicit, named\n    [Hashable α]      -- instance implicit, anonymous\n\n  def isEqual (b : α) : Bool :=\n    a == b\n\n  #check isEqual\n  -- isEqual.{u} {α : Type u} (a : α) [instBEq : BEq α] (b : α) : Bool\n\n  variable\n    {a} -- `a` is implicit now\n\n  def eqComm {b : α} := a == b ↔ b == a\n\n  #check eqComm\n  -- eqComm.{u} {α : Type u} {a : α} [instBEq : BEq α] {b : α} : Prop\nend\n```\n\nThe following shows a typical use of `variable` to factor out definition arguments:\n\n```lean\nvariable (Src : Type)\n\nstructure Logger where\n  trace : List (Src × String)\n#check Logger\n-- Logger (Src : Type) : Type\n\nnamespace Logger\n  -- switch `Src : Type` to be implicit until the `end Logger`\n  variable {Src}\n\n  def empty : Logger Src where\n    trace := []\n  #check empty\n  -- Logger.empty {Src : Type} : Logger Src\n\n  variable (log : Logger Src)\n\n  def len :=\n    log.trace.length\n  #check len\n  -- Logger.len {Src : Type} (log : Logger Src) : Nat\n\n  variable (src : Src) [BEq Src]\n\n  -- at this point all of `log`, `src`, `Src` and the `BEq` instance can all become arguments\n\n  def filterSrc :=\n    log.trace.filterMap\n      fun (src', str') =&gt; if src' == src then some str' else none\n  #check filterSrc\n  -- Logger.filterSrc {Src : Type} (log : Logger Src) (src : Src) [inst✝ : BEq Src] : List String\n\n  def lenSrc :=\n    log.filterSrc src |&gt;.length\n  #check lenSrc\n  -- Logger.lenSrc {Src : Type} (log : Logger Src) (src : Src) [inst✝ : BEq Src] : Nat\nend Logger\n```\n\nThe following example demonstrates availability of variables in proofs:\n```lean\nvariable\n  {α : Type}    -- available in the proof as indirectly mentioned through `a`\n  [ToString α]  -- available in the proof as `α` is included\n  (a : α)       -- available in the proof as mentioned in the header\n  {β : Type}    -- not available in the proof\n  [ToString β]  -- not available in the proof\n\ntheorem ex : a = a := rfl\n```\nAfter elaboration of the proof, the following warning will be generated to highlight the unused\nhypothesis:\n```\nincluded section variable '[ToString α]' is not used in 'ex', consider excluding it\n```\nIn such cases, the offending variable declaration should be moved down or into a section so that\nonly theorems that do depend on it follow it until the end of the section.\n</code>",
 "48": "<code>Fin 2</code>",
 "47": "<code>Float</code>",
 "46": "<code>A : Float^[2, 2]</code>",
 "45": "<code>Fin 3</code>",
 "44": "<code>u : Float^[3]</code>",
 "43":
 "<code>SciLean.DataArray.size.{u_1} {α : Type u_1} [pd : PlainDataType α] (self : DataArray α) : ℕ</code>",
 "42": "<code>DataArray X</code>",
 "41":
 "<code>SciLean.Size.size.{u} {α : Sort u} (a : α) [self : Size a] : ℕ</code>",
 "40":
 "<code>BasicOperations.DataArrayN.h_size {X I : Type} [PlainDataType X] [IndexType I] (self : DataArrayN X I) :\n  size I = self.data.size</code>",
 "4": "<code>fibonacci (n : ℕ) : Array ℕ</code>",
 "39":
 "<code>BasicOperations.DataArrayN.data {X I : Type} [PlainDataType X] [IndexType I] (self : DataArrayN X I) : DataArray X</code>",
 "38": "<code>SciLean.IndexType.{u} (I : Type u) : Type u</code>",
 "37":
 "<code>SciLean.PlainDataType.{u_1} (α : Type u_1) : Type u_1</code><span class=\"sep\"></span><code class=\"docstring\">This rougly corresponds to Plain Old Data(POD)/Passive Data known from OOP\n\nwiki: https://en.wikipedia.org/wiki/Passive_data_structure\n\nWe distinguish between two main types of POD. `BitType` a type that is smaller or equal to a byte and `ByteType` that takes up multiple bytes. The main motivation is an efficient storage of `Array Bool` where `Bool` takes up only a single bit, so we can fit 8 bools into a single byte and achieve significant memore reduction.\n\nPotentially surprising edge case is array of fixed length, i.e. the type `{a : Array α // a.size = n}`. It is `PlainDataType` if `α` is `PlainDataType`. However, `Array α` is not `PlainDataType`, even if `α` is `PlainDataType`, as it does not have a fixed byte size.\n</code>",
 "36": "<code>Type</code>",
 "35":
 "<code>BasicOperations.DataArrayN (X I : Type) [PlainDataType X] [IndexType I] : Type</code>",
 "34":
 "<code>BasicOperations.Fin.isLt {n : ℕ} (self : Fin n) : self.val &lt; n</code>",
 "33": "<code>BasicOperations.Fin.val {n : ℕ} (self : Fin n) : ℕ</code>",
 "32": "<code>BasicOperations.Fin (n : ℕ) : Type</code>",
 "31": "<code>Fin n</code>",
 "30": "<code>Float^[n]</code>",
 "3":
 "<code>Array.push.{u} {α : Type u} (a : Array α) (v : α) : Array α</code><span class=\"sep\"></span><code class=\"docstring\">Push an element onto the end of an array. This is amortized O(1) because\n`Array α` is internally a dynamic array.\n</code>",
 "29": "<code>dot {n : ℕ} (x y : Float^[n]) : Float</code>",
 "28": "<code><span class=\"literal string\">\"hello\"</span> : String</code>",
 "27":
 "<code>String : Type</code><span class=\"sep\"></span><code class=\"docstring\">`String` is the type of (UTF-8 encoded) strings.\n\nThe compiler overrides the data representation of this type to a byte sequence,\nand both `String.utf8ByteSize` and `String.length` are cached and O(1).\n</code>",
 "26":
 "<code>Float : Type</code><span class=\"sep\"></span><code class=\"docstring\">Native floating point type, corresponding to the IEEE 754 *binary64* format\n(`double` in C or `f64` in Rust). </code>",
 "25":
 "<code class=\"docstring\">Pattern matching. `match e, ... with | p, ... =&gt; f | ...` matches each given\nterm `e` against each pattern `p` of a match alternative. When all patterns\nof an alternative match, the `match` term evaluates to the value of the\ncorresponding right-hand side `f` with the pattern variables bound to the\nrespective matched values.\nIf used as `match h : e, ... with | p, ... =&gt; f | ...`, `h : e = p` is available\nwithin `f`.\n\nWhen not constructing a proof, `match` does not automatically substitute variables\nmatched on in dependent variables' types. Use `match (generalizing := true) ...` to\nenforce this.\n\nSyntax quotations can also be used in a pattern match.\nThis matches a `Syntax` value against quotations, pattern variables, or `_`.\n\nQuoted identifiers only match identical identifiers - custom matching such as by the preresolved\nnames only should be done explicitly.\n\n`Syntax.atom`s are ignored during matching by default except when part of a built-in literal.\nFor users introducing new atoms, we recommend wrapping them in dedicated syntax kinds if they\nshould participate in matching.\nFor example, in\n```lean\nsyntax \"c\" (\"foo\" &lt;|&gt; \"bar\") ...\n```\n`foo` and `bar` are indistinguishable during matching, but in\n```lean\nsyntax foo := \"foo\"\nsyntax \"c\" (foo &lt;|&gt; \"bar\") ...\n```\nthey are not.\n</code>",
 "24": "<code>List ℕ</code>",
 "23":
 "<code>List.reverse.{u} {α : Type u} (as : List α) : List α</code><span class=\"sep\"></span><code class=\"docstring\">`O(|as|)`. Reverse of a list:\n* `[1, 2, 3, 4].reverse = [4, 3, 2, 1]`\n\nNote that because of the \"functional but in place\" optimization implemented by Lean's compiler,\nthis function works without any allocations provided that the input list is unshared:\nit simply walks the linked list and reverses all the node pointers.\n</code>",
 "22": "<code>fibonacci.go (n : ℕ) (l : List ℕ) : List ℕ</code>",
 "21": "<code>fibonacci (n : ℕ) : List ℕ</code>",
 "20":
 "<code>List.{u} (α : Type u) : Type u</code><span class=\"sep\"></span><code class=\"docstring\">`List α` is the type of ordered lists with elements of type `α`.\nIt is implemented as a linked list.\n\n`List α` is isomorphic to `Array α`, but they are useful for different things:\n* `List α` is easier for reasoning, and\n  `Array α` is modeled as a wrapper around `List α`\n* `List α` works well as a persistent data structure, when many copies of the\n  tail are shared. When the value is not shared, `Array α` will have better\n  performance because it can do destructive updates.\n</code>",
 "2": "<code>ℕ</code>",
 "19":
 "<code>SciLean.DataArrayN.{u_3, u_4} (α : Type u_3) [pd : PlainDataType α] (ι : Type u_4) [IndexType ι] : Type</code>",
 "18": "<code>UInt64</code>",
 "175":
 "<code>Float^[8, 1, [-1:1], [-1:1]] × Float^[8, 28, 28] × Float^[30, 8, 14, 14] × Float^[30] × Float^[10, 30] × Float^[10]</code>",
 "174": "<code>DecidableEq I✝</code>",
 "173": "<code>IndexType I✝</code>",
 "172": "<code>Float^[28, 28]</code>",
 "171": "<code>Float^[10]</code>",
 "170": "<code>Float^[10, 30]</code>",
 "17":
 "<code>SciLean.DataArray.push.{u_1} {α : Type u_1} [pd : PlainDataType α] (arr : DataArray α) (val : α) (k : ℕ := 1) :\n  DataArray α</code>",
 "169": "<code>Float^[30]</code>",
 "168": "<code>Float^[30, 8, 14, 14]</code>",
 "167": "<code>Float^[8, 28, 28]</code>",
 "166": "<code>Float^[8, 1, [-1:1], [-1:1]]</code>",
 "165":
 "<code>nnet :\n  Float^[8, 1, [-1:1], [-1:1]] × Float^[8, 28, 28] × Float^[30, 8, 14, 14] × Float^[30] × Float^[10, 30] × Float^[10] →\n    (x : Float^[28, 28]) → Float^[10]</code>",
 "164": "<code>Float^[n, I]</code>",
 "163":
 "<code>dense {I : Type} [IndexType I] (n : ℕ) (A : Float^[n, I]) (b : Float^[n]) (x : Float^[I]) : Float^[n]</code>",
 "162":
 "<code class=\"docstring\">Makes names from other namespaces visible without writing the namespace prefix.\n\nNames that are made available with `open` are visible within the current `section` or `namespace`\nblock. This makes referring to (type) definitions and theorems easier, but note that it can also\nmake [scoped instances], notations, and attributes from a different namespace available.\n\nThe `open` command can be used in a few different ways:\n\n* `open Some.Namespace.Path1 Some.Namespace.Path2` makes all non-protected names in\n  `Some.Namespace.Path1` and `Some.Namespace.Path2` available without the prefix, so that\n  `Some.Namespace.Path1.x` and `Some.Namespace.Path2.y` can be referred to by writing only `x` and\n  `y`.\n\n* `open Some.Namespace.Path hiding def1 def2` opens all non-protected names in `Some.Namespace.Path`\n  except `def1` and `def2`.\n\n* `open Some.Namespace.Path (def1 def2)` only makes `Some.Namespace.Path.def1` and\n  `Some.Namespace.Path.def2` available without the full prefix, so `Some.Namespace.Path.def3` would\n  be unaffected.\n\n  This works even if `def1` and `def2` are `protected`.\n\n* `open Some.Namespace.Path renaming def1 → def1', def2 → def2'` same as `open Some.Namespace.Path\n  (def1 def2)` but `def1`/`def2`'s names are changed to `def1'`/`def2'`.\n\n  This works even if `def1` and `def2` are `protected`.\n\n* `open scoped Some.Namespace.Path1 Some.Namespace.Path2` **only** opens [scoped instances],\n  notations, and attributes from `Namespace1` and `Namespace2`; it does **not** make any other name\n  available.\n\n* `open &lt;any of the open shapes above&gt; in` makes the names `open`-ed visible only in the next\n  command or expression.\n\n[scoped instance]: https://lean-lang.org/theorem_proving_in_lean4/type_classes.html#scoped-instances\n(Scoped instances in Theorem Proving in Lean)\n\n\n## Examples\n\n```lean\n/-- SKI combinators https://en.wikipedia.org/wiki/SKI_combinator_calculus -/\nnamespace Combinator.Calculus\n  def I (a : α) : α := a\n  def K (a : α) : β → α := fun _ =&gt; a\n  def S (x : α → β → γ) (y : α → β) (z : α) : γ := x z (y z)\nend Combinator.Calculus\n\nsection\n  -- open everything under `Combinator.Calculus`, *i.e.* `I`, `K` and `S`,\n  -- until the section ends\n  open Combinator.Calculus\n\n  theorem SKx_eq_K : S K x = I := rfl\nend\n\n-- open everything under `Combinator.Calculus` only for the next command (the next `theorem`, here)\nopen Combinator.Calculus in\ntheorem SKx_eq_K' : S K x = I := rfl\n\nsection\n  -- open only `S` and `K` under `Combinator.Calculus`\n  open Combinator.Calculus (S K)\n\n  theorem SKxy_eq_y : S K x y = y := rfl\n\n  -- `I` is not in scope, we have to use its full path\n  theorem SKxy_eq_Iy : S K x y = Combinator.Calculus.I y := rfl\nend\n\nsection\n  open Combinator.Calculus\n    renaming\n      I → identity,\n      K → konstant\n\n  #check identity\n  #check konstant\nend\n\nsection\n  open Combinator.Calculus\n    hiding S\n\n  #check I\n  #check K\nend\n\nsection\n  namespace Demo\n    inductive MyType\n    | val\n\n    namespace N1\n      scoped infix:68 \" ≋ \" =&gt; BEq.beq\n\n      scoped instance : BEq MyType where\n        beq _ _ := true\n\n      def Alias := MyType\n    end N1\n  end Demo\n\n  -- bring `≋` and the instance in scope, but not `Alias`\n  open scoped Demo.N1\n\n  #check Demo.MyType.val == Demo.MyType.val\n  #check Demo.MyType.val ≋ Demo.MyType.val\n  -- #check Alias -- unknown identifier 'Alias'\nend\n```\n</code>",
 "161": "<code>Fin n₂</code>",
 "160": "<code>DecidableEq I</code>",
 "16":
 "<code>SciLean.DataArray.mkEmpty.{u_1} {α : Type u_1} [pd : PlainDataType α] (capacity : ℕ) : DataArray α</code>",
 "159": "<code>IndexType I</code>",
 "158": "<code>Fin n₁</code>",
 "157": "<code>Fin m₂</code>",
 "156": "<code>Fin m₁</code>",
 "155": "<code>autoParam (m₂ = n₂ / 2) _auto✝</code>",
 "154": "<code>autoParam (m₁ = n₁ / 2) _auto✝</code>",
 "153": "<code>Float^[I, n₁, n₂]</code>",
 "152":
 "<code>avgPool2d {n₁ n₂ : ℕ} {I : Type} [IndexType I] (x : Float^[I, n₁, n₂]) {m₁ m₂ : ℕ} (h₁ : m₁ = n₁ / 2 := by infer_var )\n  (h₂ : m₂ = n₂ / 2 := by infer_var ) : Float^[I, m₁, m₂]</code>",
 "151": "<code>_auto✝ : Lean.Syntax</code>",
 "150":
 "<code>autoParam.{u} (α : Sort u) (tactic : Lean.Syntax) : Sort u</code><span class=\"sep\"></span><code class=\"docstring\">Gadget for automatic parameter support. This is similar to the `optParam` gadget, but it uses\nthe given tactic.\nLike `optParam`, this gadget only affects elaboration.\nFor example, the tactic will *not* be invoked during type class resolution. </code>",
 "15": "<code>DataArray UInt64</code>",
 "149": "<code>autoParam (m = n / 2) _auto✝</code>",
 "148":
 "<code>avgPool {n : ℕ} (x : Float^[n]) {m : ℕ} (h : m = n / 2 := by infer_var ) : Float^[m]</code>",
 "147": "<code>Fin (2 * n)</code>",
 "146": "<code>Float^[2 * n]</code>",
 "145": "<code>avgPool {n : ℕ} (x : Float^[2 * n]) : Float^[n]</code>",
 "144": "<code>i : Fin 10</code>",
 "143":
 "<code>HAdd.hAdd.{u, v, w} {α : Type u} {β : Type v} {γ : outParam (Type w)} [self : HAdd α β γ] : α → β → γ</code><span class=\"sep\"></span><code class=\"docstring\">`a + b` computes the sum of `a` and `b`.\nThe meaning of this notation is type-dependent. </code>",
 "142":
 "<code class=\"docstring\">The `omega` tactic, for resolving integer and natural linear arithmetic problems.\n\nIt is not yet a full decision procedure (no \"dark\" or \"grey\" shadows),\nbut should be effective on many problems.\n\nWe handle hypotheses of the form `x = y`, `x &lt; y`, `x ≤ y`, and `k ∣ x` for `x y` in `Nat` or `Int`\n(and `k` a literal), along with negations of these statements.\n\nWe decompose the sides of the inequalities as linear combinations of atoms.\n\nIf we encounter `x / k` or `x % k` for literal integers `k` we introduce new auxiliary variables\nand the relevant inequalities.\n\nOn the first pass, we do not perform case splits on natural subtraction.\nIf `omega` fails, we recursively perform a case split on\na natural subtraction appearing in a hypothesis, and try again.\n\nThe options\n```\nomega +splitDisjunctions +splitNatSub +splitNatAbs +splitMinMax\n```\ncan be used to:\n* `splitDisjunctions`: split any disjunctions found in the context,\n  if the problem is not otherwise solvable.\n* `splitNatSub`: for each appearance of `((a - b : Nat) : Int)`, split on `a ≤ b` if necessary.\n* `splitNatAbs`: for each appearance of `Int.natAbs a`, split on `0 ≤ a` if necessary.\n* `splitMinMax`: for each occurrence of `min a b`, split on `min a b = a ∨ min a b = b`\nCurrently, all of these are on by default.\n</code>",
 "141":
 "<code>LT.lt.{u} {α : Type u} [self : LT α] : α → α → Prop</code><span class=\"sep\"></span><code class=\"docstring\">The less-than relation: `x &lt; y` </code>",
 "140":
 "<code>HMul.hMul.{u, v, w} {α : Type u} {β : Type v} {γ : outParam (Type w)} [self : HMul α β γ] : α → β → γ</code><span class=\"sep\"></span><code class=\"docstring\">`a * b` computes the product of `a` and `b`.\nThe meaning of this notation is type-dependent. </code>",
 "14": "<code>fibonacci (n : ℕ) : DataArray UInt64</code>",
 "139":
 "<code>HDiv.hDiv.{u, v, w} {α : Type u} {β : Type v} {γ : outParam (Type w)} [self : HDiv α β γ] : α → β → γ</code><span class=\"sep\"></span><code class=\"docstring\">`a / b` computes the result of dividing `a` by `b`.\nThe meaning of this notation is type-dependent.\n* For most types like `Nat`, `Int`, `Rat`, `Real`, `a / 0` is defined to be `0`.\n* For `Nat`, `a / b` rounds downwards.\n* For `Int`, `a / b` rounds downwards if `b` is positive or upwards if `b` is negative.\n  It is implemented as `Int.ediv`, the unique function satisfying\n  `a % b + b * (a / b) = a` and `0 ≤ a % b &lt; natAbs b` for `b ≠ 0`.\n  Other rounding conventions are available using the functions\n  `Int.fdiv` (floor rounding) and `Int.div` (truncation rounding).\n* For `Float`, `a / 0` follows the IEEE 754 semantics for division,\n  usually resulting in `inf` or `nan`. </code>",
 "138": "<code>Fin (n / 2)</code>",
 "137": "<code>avgPool {n : ℕ} (x : Float^[n]) : Float^[n / 2]</code>",
 "136": "<code>Float^[J]</code>",
 "135":
 "<code>convNd {J : Type} [IndexType J] {I : Type} [IndexType I] [VAdd J I] (w : Float^[J]) (x : Float^[I]) : Float^[I]</code>",
 "134": "<code>I'</code>",
 "133": "<code>J'</code>",
 "132": "<code>Type u_4</code>",
 "131": "<code>Type u_3</code>",
 "130": "<code>Type u_2</code>",
 "13":
 "<code>UInt64 : Type</code><span class=\"sep\"></span><code class=\"docstring\">The type of unsigned 64-bit integers. This type has special support in the\ncompiler to make it actually 64 bits rather than wrapping a `Nat`.\n</code>",
 "129": "<code>Type u_1</code>",
 "128": "<code>↑(Set.Icc a b)</code>",
 "127":
 "<code>Set.Icc.{u_1} {α : Type u_1} [Preorder α] (a b : α) : Set α</code><span class=\"sep\"></span><code class=\"docstring\">`Icc a b` is the left-closed right-closed interval $[a, b]$. </code>",
 "126":
 "<code>Fin.mk {n : ℕ} (val : ℕ) (isLt : val &lt; n) : Fin n</code><span class=\"sep\"></span><code class=\"docstring\">Creates a `Fin n` from `i : Nat` and a proof that `i &lt; n`. </code>",
 "125":
 "<code>VAdd.mk.{u, v} {G : Type u} {P : Type v} (vadd : G → P → P) : VAdd G P</code>",
 "124":
 "<code>VAdd.{u, v} (G : Type u) (P : Type v) : Type (max u v)</code><span class=\"sep\"></span><code class=\"docstring\">Type class for the `+ᵥ` notation. </code>",
 "123": "<code>J</code>",
 "122": "<code>Float^[I, n, m]</code>",
 "121": "<code>Float^[J, n, m]</code>",
 "120": "<code>Float^[J, I, [-k:k], [-k:k]]</code>",
 "12":
 "<code>SciLean.DataArray.{u_1} (α : Type u_1) [pd : PlainDataType α] : Type</code>",
 "119":
 "<code>conv2d {n m : ℕ} (k : ℤ) (J : Type) {I : Type} [IndexType I] [IndexType J] [DecidableEq J]\n  (w : Float^[J, I, [-k:k], [-k:k]]) (b : Float^[J, n, m]) (x : Float^[I, n, m]) : Float^[J, n, m]</code>",
 "118": "<code>Float^[[-k:k], [-k:k]]</code>",
 "117":
 "<code>conv2d {n m : ℕ} {k : ℤ} (w : Float^[[-k:k], [-k:k]]) (x : Float^[n, m]) : Float^[n, m]</code>",
 "116": "<code>↑(Set.Icc (-k) k)</code>",
 "115": "<code>Float^[[-k:k]]</code>",
 "114":
 "<code>conv1d {n : ℕ} {k : ℤ} (w : Float^[[-k:k]]) (x : Float^[n]) : Float^[n]</code>",
 "113":
 "<code>((Int.ofNat ↑i + j) % ↑n).toNat &lt; n</code><span class=\"sep\"></span><code class=\"docstring\">If `i : Fin n`, then `i.2` is a proof that `i.1 &lt; n`. </code>",
 "112":
 "<code>Int.toNat : ℤ → ℕ</code><span class=\"sep\"></span><code class=\"docstring\">Turns an integer into a natural number, negative numbers become\n`0`.\n\n```\n#eval (7 : Int).toNat -- 7\n#eval (0 : Int).toNat -- 0\n#eval (-7 : Int).toNat -- 0\n```\n</code>",
 "111":
 "<code>Int.ofNat : ℕ → ℤ</code><span class=\"sep\"></span><code class=\"docstring\">A natural number is an integer (`0` to `∞`). </code>",
 "110":
 "<code>ℕ</code><span class=\"sep\"></span><code class=\"docstring\">If `i : Fin n`, then `i.val : ℕ` is the described number. It can also be\nwritten as `i.1` or just `i` when the target type is known. </code>",
 "11":
 "<code class=\"docstring\">`#eval e` evaluates the expression `e` by compiling and evaluating it.\n\n* The command attempts to use `ToExpr`, `Repr`, or `ToString` instances to print the result.\n* If `e` is a monadic value of type `m ty`, then the command tries to adapt the monad `m`\n  to one of the monads that `#eval` supports, which include `IO`, `CoreM`, `MetaM`, `TermElabM`, and `CommandElabM`.\n  Users can define `MonadEval` instances to extend the list of supported monads.\n\nThe `#eval` command gracefully degrades in capability depending on what is imported.\nImporting the `Lean.Elab.Command` module provides full capabilities.\n\nDue to unsoundness, `#eval` refuses to evaluate expressions that depend on `sorry`, even indirectly,\nsince the presence of `sorry` can lead to runtime instability and crashes.\nThis check can be overridden with the `#eval! e` command.\n\nOptions:\n* If `eval.pp` is true (default: true) then tries to use `ToExpr` instances to make use of the\n  usual pretty printer. Otherwise, only tries using `Repr` and `ToString` instances.\n* If `eval.type` is true (default: false) then pretty prints the type of the evaluated value.\n* If `eval.derive.repr` is true (default: true) then attempts to auto-derive a `Repr` instance\n  when there is no other way to print the result.\n\nSee also: `#reduce e` for evaluation by term reduction.\n</code>",
 "109": "<code>ℤ</code>",
 "108": "<code>Fin.shift {n : ℕ} (i : Fin n) (j : ℤ) : Fin n</code>",
 "107": "<code>Fin k</code>",
 "106": "<code>Float^[k]</code>",
 "105":
 "<code>conv1d {n k : ℕ} (x : Float^[n]) (w : Float^[k]) : Float^[n]</code>",
 "104": "<code>Float^[n, n]</code>",
 "103": "<code>trace {n : ℕ} (A : Float^[n, n]) : Float</code>",
 "102":
 "<code>matMul {n m : ℕ} (A : Float^[n, m]) (x : Float^[m]) : Float^[n]</code>",
 "101": "<code>Fin 4</code>",
 "100": "<code>B : Float^[2, 2]</code>",
 "10":
 "<code class=\"docstring\">`return e` inside of a `do` block makes the surrounding block evaluate to `pure e`,\nskipping any further statements.\nNote that uses of the `do` keyword in other syntax like in `for _ in _ do`\ndo not constitute a surrounding block in this sense;\nin supported editors, the corresponding `do` keyword of the surrounding block\nis highlighted when hovering over `return`.\n\n`return` not followed by a term starting on the same line is equivalent to `return ()`.\n</code>",
 "1":
 "<code>Array.mkEmpty.{u} {α : Type u} (c : ℕ) : Array α</code><span class=\"sep\"></span><code class=\"docstring\">Construct a new empty array with initial capacity `c`. </code>",
 "0":
 "<code>Array.{u} (α : Type u) : Type u</code><span class=\"sep\"></span><code class=\"docstring\">`Array α` is the type of [dynamic arrays](https://en.wikipedia.org/wiki/Dynamic_array)\nwith elements from `α`. This type has special support in the runtime.\n\nAn array has a size and a capacity; the size is `Array.size` but the capacity\nis not observable from Lean code. Arrays perform best when unshared; as long\nas they are used \"linearly\" all updates will be performed destructively on the\narray, so it has comparable performance to mutable arrays in imperative\nprogramming languages.\n\nFrom the point of view of proofs `Array α` is just a wrapper around `List α`.\n</code>"}